{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of Homework2-MLDL.ipynb",
   "provenance": [
    {
     "file_id": "1495rzqiMxfqwqBjaanDwDGN7eOS4oXRX",
     "timestamp": 1588594644780
    },
    {
     "file_id": "1PhNPpklp9FbxJEtsZ8Jp9qXQa4aZDK5Y",
     "timestamp": 1586854223220
    }
   ],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-ca37dc",
   "language": "python",
   "display_name": "PyCharm (HW2)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "DokFOdD1dJEl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.vision import StandardTransform\n",
    "from torchvision.models import alexnet\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIDLJuIXK_vh",
    "colab_type": "text"
   },
   "source": [
    "**Set Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d5PkYfqfK_SA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
    "\n",
    "NUM_CLASSES = 101 # 101 + 1: There is am extra Background class that should be removed\n",
    "\n",
    "BATCH_SIZE = 64     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = 1e-2            # The initial Learning Rate\n",
    "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = 20  #30    # Total number of training epochs (iterations over dataset)\n",
    "STEP_SIZE = 5  #30    # How many epochs before decreasing learning rate (if using a step-down policy)\n",
    "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = 10"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gwii0TBHvzh",
    "colab_type": "text"
   },
   "source": [
    "**Define Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QUDdw4j2H0Mc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
    "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
    "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
    "                                      torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      # torchvision.transforms.RandomGrayscale(p=0.1),\n",
    "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Mean and Std are provided by the ImageNet documentation\n",
    "                                    ])\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                    ])\n",
    "                                  #torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      #torchvision.transforms.RandomGrayscale(p=0.1),                             # 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                                      #transforms.TenCrop(224, vertical_flip=False),"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qYIHPzYLY7i",
    "colab_type": "text"
   },
   "source": [
    "**Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QfVq_uDHLbsR",
    "colab_type": "code",
    "outputId": "e256c03e-8ce4-49ea-d576-e13c5cf37943",
    "executionInfo": {
     "status": "error",
     "timestamp": 1588595184793,
     "user_tz": -120,
     "elapsed": 1558,
     "user": {
      "displayName": "Edoardo Pinna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhD3hpmCtDKV9X0a7rGiQ2t9evyVeYOD9x69IrC=s64",
      "userId": "07286142465517714137"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    }
   },
   "source": [
    "# Clone github repository with data\n",
    "if not os.path.isdir('./Caltech101'):\n",
    "  !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
    "  os.rename('Homework2-Caltech101', 'Caltech101')\n",
    "\n",
    "DATA_DIR = 'Caltech101/'\n",
    "from Caltech101.caltech_dataset import Caltech\n",
    "\n",
    "# Prepare Pytorch train/test Datasets\n",
    "dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
    "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
    "train_indexes = np.arange(0, int(dataset.__len__()), 2)# split the indices for your train split\n",
    "val_indexes = np.arange(1, int(dataset.__len__()), 2)# split the indices for your val split\n",
    "\n",
    "train_dataset = Subset(dataset, train_indexes)\n",
    "val_dataset = Subset(dataset, val_indexes)\n",
    "\n",
    "# Check dataset sizes\n",
    "print('Train Dataset: {}'.format(len(train_dataset)))\n",
    "print('Valid Dataset: {}'.format(len(val_dataset)))\n",
    "print('Test Dataset: {}'.format(len(test_dataset)))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n",
      "101 {'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'accordion': 5, 'airplanes': 6, 'anchor': 7, 'ant': 8, 'barrel': 9, 'bass': 10, 'beaver': 11, 'binocular': 12, 'bonsai': 13, 'brain': 14, 'brontosaurus': 15, 'buddha': 16, 'butterfly': 17, 'camera': 18, 'cannon': 19, 'car_side': 20, 'ceiling_fan': 21, 'cellphone': 22, 'chair': 23, 'chandelier': 24, 'cougar_body': 25, 'cougar_face': 26, 'crab': 27, 'crayfish': 28, 'crocodile': 29, 'crocodile_head': 30, 'cup': 31, 'dalmatian': 32, 'dollar_bill': 33, 'dolphin': 34, 'dragonfly': 35, 'electric_guitar': 36, 'elephant': 37, 'emu': 38, 'euphonium': 39, 'ewer': 40, 'ferry': 41, 'flamingo': 42, 'flamingo_head': 43, 'garfield': 44, 'gerenuk': 45, 'gramophone': 46, 'grand_piano': 47, 'hawksbill': 48, 'headphone': 49, 'hedgehog': 50, 'helicopter': 51, 'ibis': 52, 'inline_skate': 53, 'joshua_tree': 54, 'kangaroo': 55, 'ketch': 56, 'lamp': 57, 'laptop': 58, 'llama': 59, 'lobster': 60, 'lotus': 61, 'mandolin': 62, 'mayfly': 63, 'menorah': 64, 'metronome': 65, 'minaret': 66, 'nautilus': 67, 'octopus': 68, 'okapi': 69, 'pagoda': 70, 'panda': 71, 'pigeon': 72, 'pizza': 73, 'platypus': 74, 'pyramid': 75, 'revolver': 76, 'rhino': 77, 'rooster': 78, 'saxophone': 79, 'schooner': 80, 'scissors': 81, 'scorpion': 82, 'sea_horse': 83, 'snoopy': 84, 'soccer_ball': 85, 'stapler': 86, 'starfish': 87, 'stegosaurus': 88, 'stop_sign': 89, 'strawberry': 90, 'sunflower': 91, 'tick': 92, 'trilobite': 93, 'umbrella': 94, 'watch': 95, 'water_lilly': 96, 'wheelchair': 97, 'wild_cat': 98, 'windsor_chair': 99, 'wrench': 100, 'yin_yang': 101}\n",
      "iterations without BACKGROUND 5784\n",
      "iterations with BACKGROUND 6096\n",
      "Number of images of train = 5784 \n",
      "Number of images of train without BACKGROUND_Google Class = 5784 \n",
      "len 101\n",
      "102 ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n",
      "101 {'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'accordion': 5, 'airplanes': 6, 'anchor': 7, 'ant': 8, 'barrel': 9, 'bass': 10, 'beaver': 11, 'binocular': 12, 'bonsai': 13, 'brain': 14, 'brontosaurus': 15, 'buddha': 16, 'butterfly': 17, 'camera': 18, 'cannon': 19, 'car_side': 20, 'ceiling_fan': 21, 'cellphone': 22, 'chair': 23, 'chandelier': 24, 'cougar_body': 25, 'cougar_face': 26, 'crab': 27, 'crayfish': 28, 'crocodile': 29, 'crocodile_head': 30, 'cup': 31, 'dalmatian': 32, 'dollar_bill': 33, 'dolphin': 34, 'dragonfly': 35, 'electric_guitar': 36, 'elephant': 37, 'emu': 38, 'euphonium': 39, 'ewer': 40, 'ferry': 41, 'flamingo': 42, 'flamingo_head': 43, 'garfield': 44, 'gerenuk': 45, 'gramophone': 46, 'grand_piano': 47, 'hawksbill': 48, 'headphone': 49, 'hedgehog': 50, 'helicopter': 51, 'ibis': 52, 'inline_skate': 53, 'joshua_tree': 54, 'kangaroo': 55, 'ketch': 56, 'lamp': 57, 'laptop': 58, 'llama': 59, 'lobster': 60, 'lotus': 61, 'mandolin': 62, 'mayfly': 63, 'menorah': 64, 'metronome': 65, 'minaret': 66, 'nautilus': 67, 'octopus': 68, 'okapi': 69, 'pagoda': 70, 'panda': 71, 'pigeon': 72, 'pizza': 73, 'platypus': 74, 'pyramid': 75, 'revolver': 76, 'rhino': 77, 'rooster': 78, 'saxophone': 79, 'schooner': 80, 'scissors': 81, 'scorpion': 82, 'sea_horse': 83, 'snoopy': 84, 'soccer_ball': 85, 'stapler': 86, 'starfish': 87, 'stegosaurus': 88, 'stop_sign': 89, 'strawberry': 90, 'sunflower': 91, 'tick': 92, 'trilobite': 93, 'umbrella': 94, 'watch': 95, 'water_lilly': 96, 'wheelchair': 97, 'wild_cat': 98, 'windsor_chair': 99, 'wrench': 100, 'yin_yang': 101}\n",
      "iterations without BACKGROUND 2893\n",
      "iterations with BACKGROUND 3049\n",
      "Number of images of test = 2893 \n",
      "Number of images of test without BACKGROUND_Google Class = 2893 \n",
      "len 101\n",
      "Train Dataset: 2892\n",
      "Valid Dataset: 2892\n",
      "Test Dataset: 2893\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYEDQ7Z21ldN",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Prepare Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VriRw8SI1nle",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=int(BATCH_SIZE), shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=int(BATCH_SIZE/2), shuffle=False, num_workers=4) #Batch_size decrease for GPU ram problems"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbZ1t5Qs2z4j",
    "colab_type": "text"
   },
   "source": [
    "**Prepare Network**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "exHUjtXa22DN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = alexnet(pretrained=True, progress=True) # Loading AlexNet model\n",
    "best_net = alexnet()\n",
    "# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes\n",
    "# We need 101 outputs for Caltech-101\n",
    "net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer\n",
    "                                                 # The convolutional layer is nn.Conv2d\n",
    "for i, (name, param) in enumerate(net.named_parameters()):\n",
    "  if i < 10:  param.requires_grad = False\n",
    "# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs\n",
    "# It is strongly suggested to study torchvision.models.alexnet source code"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features.0.weight Parameter containing:\n",
      "tensor([[[[ 1.1864e-01,  9.4069e-02,  9.5435e-02,  ...,  5.5822e-02,\n",
      "            2.1575e-02,  4.9963e-02],\n",
      "          [ 7.4882e-02,  3.8940e-02,  5.2979e-02,  ...,  2.5709e-02,\n",
      "           -1.1299e-02,  4.1590e-03],\n",
      "          [ 7.5425e-02,  3.8779e-02,  5.4930e-02,  ...,  4.3596e-02,\n",
      "            1.0225e-02,  1.3251e-02],\n",
      "          ...,\n",
      "          [ 9.3155e-02,  1.0374e-01,  6.7547e-02,  ..., -2.0277e-01,\n",
      "           -1.2839e-01, -1.1220e-01],\n",
      "          [ 4.3544e-02,  6.4916e-02,  3.6164e-02,  ..., -2.0248e-01,\n",
      "           -1.1376e-01, -1.0719e-01],\n",
      "          [ 4.7369e-02,  6.2543e-02,  2.4758e-02,  ..., -1.1844e-01,\n",
      "           -9.5567e-02, -8.3890e-02]],\n",
      "\n",
      "         [[-7.2634e-02, -5.7996e-02, -8.0661e-02,  ..., -6.0304e-04,\n",
      "           -2.5309e-02,  2.5471e-02],\n",
      "          [-6.9042e-02, -6.7562e-02, -7.6367e-02,  ..., -3.9616e-03,\n",
      "           -3.0402e-02,  1.0477e-02],\n",
      "          [-9.9517e-02, -8.5592e-02, -1.0521e-01,  ..., -2.6587e-02,\n",
      "           -2.2777e-02,  6.6451e-03],\n",
      "          ...,\n",
      "          [-1.5121e-01, -8.8735e-02, -9.6737e-02,  ...,  3.0853e-01,\n",
      "            1.8096e-01,  8.4297e-02],\n",
      "          [-1.4309e-01, -7.5710e-02, -7.2215e-02,  ...,  2.0417e-01,\n",
      "            1.6447e-01,  9.5166e-02],\n",
      "          [-8.5925e-02, -4.0134e-02, -5.1491e-02,  ...,  1.6352e-01,\n",
      "            1.4822e-01,  1.0196e-01]],\n",
      "\n",
      "         [[-2.3596e-02, -2.1258e-03, -2.7761e-02,  ...,  3.9940e-02,\n",
      "           -7.1123e-03,  3.2207e-02],\n",
      "          [ 2.5705e-04,  2.2468e-02,  8.9070e-03,  ...,  1.8771e-02,\n",
      "           -1.4155e-02,  1.8275e-02],\n",
      "          [ 5.4084e-03,  2.9397e-02,  3.3051e-04,  ...,  1.2054e-02,\n",
      "           -2.5237e-03,  8.3515e-03],\n",
      "          ...,\n",
      "          [-6.2826e-02, -1.1655e-02, -6.2080e-02,  ...,  1.0332e-01,\n",
      "           -9.4987e-03, -7.9570e-02],\n",
      "          [-4.5691e-02,  3.3726e-03, -3.9632e-02,  ..., -2.6448e-02,\n",
      "           -3.3500e-02, -7.6398e-02],\n",
      "          [-1.8700e-02,  1.1365e-02, -3.9671e-02,  ..., -6.8563e-02,\n",
      "           -4.1289e-02, -5.5473e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9950e-03,  2.9262e-03,  4.8212e-02,  ...,  6.1402e-02,\n",
      "            2.6121e-02,  1.9558e-02],\n",
      "          [-1.2579e-02, -4.8879e-03,  1.8490e-02,  ...,  5.3881e-02,\n",
      "            1.6377e-02,  2.3768e-02],\n",
      "          [ 3.6561e-03, -7.7510e-04,  2.6360e-02,  ..., -2.5849e-02,\n",
      "           -6.1798e-02,  2.6103e-02],\n",
      "          ...,\n",
      "          [-1.0812e-02, -4.6008e-03,  1.5122e-02,  ...,  2.9561e-02,\n",
      "            5.3272e-03,  6.8561e-02],\n",
      "          [ 2.7364e-04, -1.4850e-02,  7.8180e-03,  ...,  2.7172e-02,\n",
      "           -1.8095e-02,  5.2485e-02],\n",
      "          [-5.2470e-02, -4.6578e-02, -1.0951e-02,  ...,  4.3038e-03,\n",
      "           -2.6379e-03,  1.4406e-02]],\n",
      "\n",
      "         [[ 2.3965e-02,  2.2740e-02,  5.7586e-03,  ...,  7.2087e-03,\n",
      "           -2.4652e-02,  4.4658e-02],\n",
      "          [ 2.6914e-02,  4.4892e-02, -1.0872e-03,  ...,  4.4243e-02,\n",
      "           -2.1168e-02,  6.4538e-02],\n",
      "          [ 1.2421e-02,  1.0247e-02, -4.1554e-02,  ..., -1.2134e-01,\n",
      "           -1.6294e-01,  2.6266e-02],\n",
      "          ...,\n",
      "          [ 3.5926e-02,  5.3235e-02,  1.1016e-02,  ...,  1.2710e-02,\n",
      "           -2.9737e-02,  8.5926e-02],\n",
      "          [ 1.5623e-02,  2.1743e-02, -8.2941e-03,  ..., -3.2744e-03,\n",
      "           -5.4099e-02,  5.7634e-02],\n",
      "          [ 7.5254e-02,  8.7784e-02,  5.5804e-02,  ...,  5.2849e-02,\n",
      "            1.0612e-02,  9.3531e-02]],\n",
      "\n",
      "         [[-3.6488e-02,  6.6332e-03, -3.9035e-02,  ..., -1.5678e-02,\n",
      "           -7.9994e-02, -8.8658e-04],\n",
      "          [-5.1740e-03,  5.7395e-02,  8.9841e-03,  ...,  7.4166e-02,\n",
      "           -3.1792e-03,  4.2777e-02],\n",
      "          [-7.9446e-02, -2.2924e-02, -7.3370e-02,  ..., -5.6738e-02,\n",
      "           -1.2923e-01,  1.8896e-02],\n",
      "          ...,\n",
      "          [-3.9394e-02,  3.0981e-02, -2.7901e-02,  ..., -1.6774e-02,\n",
      "           -1.0236e-01,  4.0128e-02],\n",
      "          [-6.0751e-02, -2.3034e-02, -7.6838e-02,  ..., -7.9069e-02,\n",
      "           -1.6195e-01, -1.3746e-02],\n",
      "          [ 7.9522e-03,  4.6969e-02, -1.2460e-02,  ..., -4.6956e-02,\n",
      "           -1.0082e-01,  1.9832e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1702e-02,  1.3825e-02,  9.0514e-03,  ..., -9.6401e-02,\n",
      "           -1.1277e-01, -2.1596e-01],\n",
      "          [-9.0091e-02, -1.3136e-02, -3.2812e-02,  ..., -7.5263e-02,\n",
      "           -1.4803e-01, -2.9966e-01],\n",
      "          [-1.3155e-01, -4.2686e-02, -4.7744e-02,  ...,  2.1429e-01,\n",
      "            3.2543e-02, -1.7151e-01],\n",
      "          ...,\n",
      "          [-1.0621e-01, -9.7966e-02, -2.5551e-01,  ...,  1.2277e-01,\n",
      "            1.9287e-01,  1.2671e-01],\n",
      "          [-8.0761e-02, -6.1498e-02, -2.2312e-01,  ...,  3.5376e-02,\n",
      "            1.0532e-01,  1.0669e-01],\n",
      "          [ 3.8186e-02,  4.9957e-02, -1.2802e-01,  ..., -3.2927e-02,\n",
      "            1.8685e-02,  4.7146e-02]],\n",
      "\n",
      "         [[ 3.9013e-02,  6.4311e-03, -3.1710e-03,  ..., -2.1245e-02,\n",
      "            4.0516e-02,  1.1092e-01],\n",
      "          [ 6.5689e-02,  2.2132e-02,  6.6539e-03,  ..., -3.9448e-02,\n",
      "            2.7749e-02,  1.1404e-01],\n",
      "          [ 7.7954e-02,  4.0220e-02,  1.4047e-02,  ..., -1.5417e-01,\n",
      "           -9.2291e-02,  3.4460e-02],\n",
      "          ...,\n",
      "          [ 1.2836e-01,  9.4449e-02,  1.4659e-01,  ..., -6.0067e-02,\n",
      "           -9.0891e-02, -6.1129e-02],\n",
      "          [ 1.2683e-01,  1.0044e-01,  1.3754e-01,  ..., -2.2507e-02,\n",
      "           -6.6664e-02, -1.9906e-02],\n",
      "          [ 8.0509e-02,  7.8203e-02,  9.8934e-02,  ...,  9.2865e-03,\n",
      "           -3.4635e-02, -1.2395e-02]],\n",
      "\n",
      "         [[ 1.1535e-02, -2.6993e-02,  1.4820e-02,  ...,  9.4833e-02,\n",
      "            1.2044e-01,  1.1027e-01],\n",
      "          [ 9.2629e-03, -2.6680e-02,  1.2218e-02,  ...,  8.7219e-02,\n",
      "            1.5435e-01,  1.8049e-01],\n",
      "          [ 6.9946e-02,  1.3250e-02,  4.8007e-02,  ..., -5.6851e-02,\n",
      "            3.2596e-02,  1.6812e-01],\n",
      "          ...,\n",
      "          [-1.2187e-02, -3.3265e-02,  1.1284e-01,  ..., -6.7740e-02,\n",
      "           -1.0240e-01, -7.6188e-02],\n",
      "          [-6.0069e-03, -2.8631e-02,  1.1643e-01,  ..., -6.7597e-03,\n",
      "           -4.3772e-02, -3.1101e-02],\n",
      "          [-1.3355e-01, -1.4825e-01, -1.0060e-03,  ...,  1.8809e-02,\n",
      "           -6.4637e-03, -2.7061e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.0948e-03,  1.4823e-02,  4.7374e-03,  ...,  1.5540e-02,\n",
      "           -5.8369e-04, -1.9922e-02],\n",
      "          [ 2.8962e-04,  2.1229e-02, -1.3210e-02,  ...,  2.4388e-03,\n",
      "           -5.8485e-03, -2.0373e-02],\n",
      "          [-1.1050e-02,  1.0094e-02, -2.9625e-02,  ..., -1.4471e-02,\n",
      "           -1.7187e-02, -3.0534e-02],\n",
      "          ...,\n",
      "          [ 1.0013e-01,  9.1407e-02,  1.3077e-01,  ...,  1.5798e-01,\n",
      "            9.0361e-02,  7.8365e-02],\n",
      "          [ 1.1610e-01,  8.1846e-02,  8.2892e-02,  ..., -6.0174e-02,\n",
      "           -6.9412e-02, -5.0151e-02],\n",
      "          [-1.0564e-01, -1.1848e-01, -1.7681e-01,  ..., -2.0837e-01,\n",
      "           -1.8036e-01, -1.6691e-01]],\n",
      "\n",
      "         [[-1.1495e-02,  2.4917e-03, -8.2400e-03,  ..., -7.5865e-03,\n",
      "           -1.7387e-02, -1.7026e-02],\n",
      "          [-2.7461e-03, -1.1415e-02, -6.0670e-03,  ..., -2.8248e-02,\n",
      "           -2.2555e-02, -2.2559e-02],\n",
      "          [-8.4246e-03, -2.2378e-03, -3.5825e-02,  ..., -1.8462e-02,\n",
      "           -1.9795e-02, -2.4990e-02],\n",
      "          ...,\n",
      "          [ 1.2956e-01,  9.8057e-02,  1.4888e-01,  ...,  1.5655e-01,\n",
      "            7.9547e-02,  9.6928e-02],\n",
      "          [ 1.6080e-01,  1.0522e-01,  1.0264e-01,  ..., -6.5226e-02,\n",
      "           -6.4314e-02, -3.9066e-02],\n",
      "          [-1.2880e-01, -1.4656e-01, -1.9475e-01,  ..., -2.4177e-01,\n",
      "           -2.0277e-01, -1.9324e-01]],\n",
      "\n",
      "         [[-5.4209e-03, -1.7648e-03,  4.3163e-03,  ...,  9.8182e-03,\n",
      "            5.2347e-03,  6.3336e-03],\n",
      "          [ 9.3478e-03,  1.5920e-03, -2.1660e-03,  ...,  7.1244e-03,\n",
      "            9.3521e-04, -5.7647e-03],\n",
      "          [-1.3668e-03,  3.8899e-03, -7.7412e-03,  ...,  3.0651e-03,\n",
      "            1.4989e-02, -8.1730e-03],\n",
      "          ...,\n",
      "          [ 4.3937e-02,  7.9544e-04,  6.0613e-02,  ...,  7.4787e-02,\n",
      "            4.3960e-02,  5.6071e-02],\n",
      "          [ 1.0077e-01,  7.5126e-02,  1.0962e-01,  ...,  4.9886e-03,\n",
      "            1.0789e-02,  1.3402e-02],\n",
      "          [-8.8773e-02, -7.2790e-02, -9.2907e-02,  ..., -6.6530e-02,\n",
      "           -3.8977e-02, -4.8370e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5712e-03,  4.6908e-02, -1.6075e-02,  ...,  7.7790e-03,\n",
      "           -1.9798e-02,  6.8000e-03],\n",
      "          [ 6.2769e-02,  4.5108e-02,  4.7187e-02,  ...,  6.0599e-02,\n",
      "            2.9275e-02,  5.5794e-02],\n",
      "          [ 3.6748e-03,  1.2952e-02,  1.8988e-05,  ..., -8.3492e-03,\n",
      "           -1.9689e-03,  8.0830e-03],\n",
      "          ...,\n",
      "          [-4.4365e-02, -5.8858e-02, -2.4772e-02,  ..., -2.8423e-02,\n",
      "           -3.0897e-02, -5.2936e-02],\n",
      "          [-9.7572e-03, -4.3227e-02,  9.0068e-03,  ..., -4.2596e-02,\n",
      "           -1.8114e-02, -2.8028e-02],\n",
      "          [-2.2007e-02, -3.3594e-02,  1.3479e-02,  ..., -4.1530e-02,\n",
      "           -1.7819e-02, -5.1977e-02]],\n",
      "\n",
      "         [[-9.0596e-02, -5.1485e-02, -1.6459e-01,  ..., -1.1970e-01,\n",
      "           -1.1150e-01, -4.3914e-02],\n",
      "          [ 1.3835e-02,  2.6007e-02, -1.9440e-02,  ...,  2.3757e-02,\n",
      "            6.3709e-03,  5.4287e-02],\n",
      "          [-9.3225e-02, -4.7454e-02, -1.1274e-01,  ..., -8.6459e-02,\n",
      "           -7.3958e-02, -6.6610e-02],\n",
      "          ...,\n",
      "          [ 2.7382e-02,  1.0310e-02,  4.3906e-02,  ...,  2.7094e-02,\n",
      "            4.4510e-02,  1.5977e-02],\n",
      "          [ 9.8431e-02,  6.1433e-02,  1.1413e-01,  ...,  9.6398e-02,\n",
      "            1.0725e-01,  9.5719e-02],\n",
      "          [-1.5100e-02, -1.1830e-02,  4.8571e-02,  ...,  2.9060e-02,\n",
      "            5.6323e-02, -2.1631e-03]],\n",
      "\n",
      "         [[-1.3693e-01, -7.9341e-02, -2.1245e-01,  ..., -1.3633e-01,\n",
      "           -1.5123e-01, -6.3938e-02],\n",
      "          [ 1.5745e-02,  5.1443e-02, -1.8209e-02,  ...,  4.9085e-02,\n",
      "            1.9585e-02,  7.8095e-02],\n",
      "          [-1.7127e-01, -8.8734e-02, -1.7467e-01,  ..., -1.4431e-01,\n",
      "           -1.3364e-01, -1.1878e-01],\n",
      "          ...,\n",
      "          [ 5.1982e-02,  1.5912e-02,  7.0009e-02,  ...,  4.4396e-02,\n",
      "            6.5429e-02,  2.6919e-02],\n",
      "          [ 1.3144e-01,  9.1333e-02,  1.6228e-01,  ...,  1.4230e-01,\n",
      "            1.5500e-01,  1.3808e-01],\n",
      "          [ 3.7818e-03, -2.0365e-02,  7.8663e-02,  ...,  8.6037e-02,\n",
      "            1.2596e-01,  3.8774e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.5081e-02,  5.6581e-02,  1.4016e-01,  ..., -1.4826e-02,\n",
      "            1.0425e-02, -3.7919e-03],\n",
      "          [ 6.0412e-02,  1.2531e-01, -1.2366e-01,  ...,  7.8628e-02,\n",
      "           -1.0564e-02, -2.2228e-02],\n",
      "          [ 1.0304e-01, -1.3654e-01, -1.9601e-01,  ..., -5.1919e-02,\n",
      "           -8.3287e-02,  3.9678e-02],\n",
      "          ...,\n",
      "          [-1.8598e-01,  1.5479e-02,  3.3912e-01,  ...,  2.7509e-01,\n",
      "            1.0493e-01, -1.6863e-01],\n",
      "          [ 6.8278e-02,  1.3989e-01,  1.1350e-02,  ..., -7.8728e-02,\n",
      "           -2.5001e-01, -8.0072e-02],\n",
      "          [ 5.1736e-03, -6.8372e-02, -9.1940e-02,  ..., -1.0727e-01,\n",
      "            8.7973e-02,  1.0139e-01]],\n",
      "\n",
      "         [[-9.8760e-02,  6.2635e-02,  1.1495e-01,  ..., -1.3191e-02,\n",
      "            1.9574e-02, -1.0864e-03],\n",
      "          [ 8.3206e-02,  1.0300e-01, -1.5419e-01,  ...,  1.0864e-01,\n",
      "            1.2592e-02, -2.0278e-02],\n",
      "          [ 1.1248e-01, -1.6928e-01, -1.8876e-01,  ..., -6.3491e-02,\n",
      "           -9.3101e-02,  4.9006e-02],\n",
      "          ...,\n",
      "          [-1.8867e-01,  6.7374e-02,  4.8128e-01,  ...,  3.1371e-01,\n",
      "            1.6068e-01, -1.3449e-01],\n",
      "          [ 1.1207e-01,  2.0871e-01,  4.6815e-02,  ..., -7.0456e-03,\n",
      "           -2.2978e-01, -6.9528e-02],\n",
      "          [ 1.7255e-02, -9.1683e-02, -1.5943e-01,  ..., -8.0373e-02,\n",
      "            8.0035e-02,  1.1819e-01]],\n",
      "\n",
      "         [[-1.0580e-01,  5.4381e-02,  1.3048e-01,  ..., -3.9546e-02,\n",
      "            1.1924e-02, -2.7886e-03],\n",
      "          [ 5.7859e-02,  1.0646e-01, -1.3468e-01,  ...,  1.0645e-01,\n",
      "            1.8412e-02, -1.3245e-03],\n",
      "          [ 1.0398e-01, -1.0849e-01, -1.6758e-01,  ..., -4.2554e-02,\n",
      "           -8.5875e-02,  5.2581e-02],\n",
      "          ...,\n",
      "          [-1.8241e-01,  5.4228e-02,  3.9395e-01,  ...,  2.4432e-01,\n",
      "            1.0216e-01, -1.2876e-01],\n",
      "          [ 8.5720e-02,  1.8378e-01,  5.0316e-02,  ..., -4.7009e-02,\n",
      "           -2.1584e-01, -4.2482e-02],\n",
      "          [ 3.9612e-02, -7.6353e-02, -1.3502e-01,  ..., -4.8630e-02,\n",
      "            1.0063e-01,  9.0307e-02]]]], requires_grad=True)\n",
      "1 features.0.bias Parameter containing:\n",
      "tensor([-0.9705, -2.8070, -0.0371, -0.0795, -0.1159,  0.0252, -0.0752, -1.4181,\n",
      "         1.6454, -0.0990, -0.0161, -0.1282, -0.0658, -0.0345, -0.0743, -1.2977,\n",
      "        -0.0505,  0.0121, -0.1013, -1.1887, -0.1380, -0.0492, -0.0789, -0.0405,\n",
      "        -0.0958, -0.0705, -1.9374, -0.0850, -0.1388, -0.1968, -0.1279, -2.0095,\n",
      "        -0.0476, -0.0604, -0.0351, -0.3843, -2.7823,  0.6605, -0.1655, -2.1293,\n",
      "         0.0543, -0.0274, -0.1703, -0.0593, -0.4215, -1.9394, -1.2094,  0.0153,\n",
      "        -0.1081, -0.0248, -0.1503, -1.8516, -0.0928, -0.0177, -0.0700, -0.0582,\n",
      "        -0.0630, -0.0721, -1.2678, -0.1176, -0.0441, -0.3259,  0.0507, -0.0146],\n",
      "       requires_grad=True)\n",
      "2 features.3.weight Parameter containing:\n",
      "tensor([[[[ 3.6245e-03,  1.4335e-03,  3.7217e-02, -2.0926e-02,  1.8121e-03],\n",
      "          [ 2.4126e-02, -1.2056e-02,  7.1170e-02, -8.5224e-02,  1.3067e-02],\n",
      "          [ 2.0966e-02, -1.0623e-01,  2.1572e-02, -6.9547e-02,  3.1583e-02],\n",
      "          [-8.3392e-03, -3.9020e-02, -4.6621e-02,  2.2133e-02, -1.3252e-03],\n",
      "          [-1.5370e-02,  8.6569e-03,  3.1479e-02,  1.6698e-02, -4.7130e-03]],\n",
      "\n",
      "         [[-5.4573e-03, -1.9087e-02, -3.2424e-02, -2.2006e-02, -1.2120e-02],\n",
      "          [-7.4972e-03,  3.0946e-02,  3.1899e-02, -7.6327e-03, -1.4720e-02],\n",
      "          [ 5.4830e-03,  8.0306e-02,  6.1262e-02,  1.3252e-02,  2.6240e-02],\n",
      "          [-2.6938e-02,  5.9188e-03,  3.8373e-02, -6.3116e-03,  3.9863e-03],\n",
      "          [ 2.0844e-03, -3.6292e-02, -2.1987e-03, -1.6570e-02,  5.6354e-03]],\n",
      "\n",
      "         [[-1.2587e-02, -5.9436e-02, -9.6281e-02,  1.6745e-02,  4.7471e-02],\n",
      "          [-1.5036e-02, -1.1214e-01, -2.3924e-02,  3.3459e-02,  4.1306e-02],\n",
      "          [-1.3845e-02,  4.1235e-02,  2.1580e-01,  2.9520e-02, -5.8914e-02],\n",
      "          [ 1.2300e-02,  1.0087e-01,  2.1916e-02, -1.4008e-01, -3.1255e-02],\n",
      "          [ 3.7845e-02,  5.2634e-02, -8.0348e-03, -8.1815e-02,  1.4355e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2711e-02,  2.5915e-02,  4.1726e-02, -1.3706e-02,  1.4752e-03],\n",
      "          [-1.0794e-02,  1.6434e-02,  8.1224e-02, -6.0144e-02, -5.1132e-02],\n",
      "          [-1.3769e-02, -5.3764e-02,  1.1054e-01,  3.8881e-03, -5.8872e-02],\n",
      "          [ 5.1748e-04,  2.3237e-02,  6.1570e-02,  5.5012e-02, -1.8824e-02],\n",
      "          [-4.0024e-03,  9.4621e-03, -2.7666e-02, -3.6102e-03, -6.4362e-03]],\n",
      "\n",
      "         [[-9.5948e-04, -5.7705e-03,  4.5656e-02,  1.4085e-02, -4.3562e-02],\n",
      "          [-4.4058e-03, -3.2867e-02,  4.1615e-02, -1.0995e-02,  2.3037e-02],\n",
      "          [ 1.7953e-02,  5.5599e-03, -4.6110e-02, -6.3326e-02,  2.5256e-02],\n",
      "          [ 5.1608e-03,  4.1085e-02,  2.1804e-02,  1.9433e-02,  3.1380e-02],\n",
      "          [-2.9532e-02, -3.1130e-03,  5.4939e-02,  3.5771e-02, -3.1513e-03]],\n",
      "\n",
      "         [[ 1.7368e-03,  1.5858e-02, -3.9606e-02, -8.6650e-02,  4.2392e-02],\n",
      "          [ 3.2755e-02,  2.0259e-02,  1.4398e-01, -1.5988e-01, -1.1522e-01],\n",
      "          [ 1.1646e-02, -1.3281e-01,  2.5051e-01,  1.9387e-01, -1.4720e-01],\n",
      "          [ 2.9876e-02, -7.6454e-02, -1.3301e-01,  1.2492e-01,  3.0456e-02],\n",
      "          [ 4.8693e-02,  7.8451e-02, -3.9283e-02,  4.8439e-03,  2.0383e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1691e-02, -4.7307e-02,  3.3946e-02,  6.8847e-03,  2.6204e-02],\n",
      "          [ 1.7683e-02, -5.2123e-02, -6.2835e-02, -3.3933e-02,  1.9128e-02],\n",
      "          [ 9.2291e-03, -2.8800e-02, -1.8724e-01, -1.9551e-02, -2.1082e-02],\n",
      "          [-1.4346e-02,  5.7543e-02, -4.1899e-02,  6.3682e-03,  4.2324e-04],\n",
      "          [ 1.2244e-02,  2.3090e-02, -2.2817e-02,  2.3080e-03, -6.4166e-03]],\n",
      "\n",
      "         [[ 4.6469e-03,  7.4133e-03, -4.1122e-02,  2.9806e-02, -1.8110e-02],\n",
      "          [ 9.6099e-03,  3.9877e-02, -4.1848e-02,  6.9251e-03, -2.5908e-02],\n",
      "          [-1.0007e-02,  5.4747e-02,  2.6736e-02,  7.0483e-03,  2.6949e-02],\n",
      "          [-9.5527e-03, -3.6075e-02,  1.4897e-02, -1.2595e-02, -1.8202e-02],\n",
      "          [-1.4465e-04, -6.3873e-02,  5.8016e-02,  2.8762e-02, -9.7704e-04]],\n",
      "\n",
      "         [[-4.5600e-02,  9.9321e-02,  2.0830e-02, -1.7641e-02,  4.3317e-03],\n",
      "          [-1.1306e-01,  1.0613e-01,  1.2299e-01, -1.5599e-02,  1.1943e-02],\n",
      "          [-8.6221e-02,  5.1575e-02,  2.8114e-01,  3.8475e-03,  3.9631e-02],\n",
      "          [ 2.7465e-02, -9.6338e-02,  1.6717e-01,  1.7882e-02, -3.1237e-02],\n",
      "          [ 3.8818e-02, -1.5017e-01,  9.5537e-02,  8.2108e-02, -2.6467e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1779e-03,  8.2149e-03,  2.2985e-02, -4.9943e-03, -2.2914e-02],\n",
      "          [ 4.4609e-03,  4.6661e-02,  3.4394e-02,  5.2542e-02, -1.8957e-02],\n",
      "          [-1.4202e-02,  5.9543e-02,  6.0551e-03,  3.6463e-02,  3.2430e-04],\n",
      "          [-2.9488e-02,  4.5902e-02,  5.4980e-02, -2.6936e-03,  4.2663e-03],\n",
      "          [-2.9711e-02, -1.6390e-02,  3.4428e-02, -9.1090e-03, -9.7971e-03]],\n",
      "\n",
      "         [[ 2.0002e-02, -4.4658e-03, -2.8359e-02,  7.4180e-03, -5.3517e-03],\n",
      "          [ 1.3052e-02, -2.9312e-02, -6.5957e-02,  3.1932e-02, -2.3129e-03],\n",
      "          [ 1.4003e-02, -5.7715e-02, -9.1541e-02,  2.8261e-03,  1.8726e-02],\n",
      "          [-1.8143e-02, -4.5023e-02, -9.9762e-03,  1.2348e-02, -1.4161e-03],\n",
      "          [ 3.3575e-03,  1.8285e-02,  1.2383e-02, -2.0430e-02,  2.4573e-02]],\n",
      "\n",
      "         [[-5.4195e-03,  4.5804e-04,  1.7469e-02, -2.2458e-03,  1.7530e-03],\n",
      "          [-1.0281e-02,  3.1367e-02, -2.5485e-02,  1.2870e-02, -7.0466e-04],\n",
      "          [-6.3459e-03,  7.3701e-02, -2.9366e-02,  4.9803e-02,  2.5816e-02],\n",
      "          [-1.9934e-02,  3.8506e-02,  3.0833e-02,  2.5688e-03, -4.4185e-03],\n",
      "          [ 1.8114e-03,  2.3094e-02,  4.6518e-02, -3.3974e-02, -1.1660e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0163e-02, -3.7849e-02, -4.6664e-02, -9.7829e-03,  3.7624e-02],\n",
      "          [ 1.4684e-01, -6.4947e-02, -3.7485e-02, -9.2710e-03,  2.3640e-02],\n",
      "          [ 1.8563e-02, -3.5328e-02, -9.6485e-03,  1.4210e-02,  2.7077e-02],\n",
      "          [-6.7717e-03,  2.8039e-03,  4.6860e-03,  4.7567e-03, -6.6633e-03],\n",
      "          [ 2.2155e-02, -1.2387e-03,  3.1133e-02,  3.1837e-02,  2.4495e-03]],\n",
      "\n",
      "         [[ 2.2964e-02, -3.2592e-02, -1.7921e-02,  5.2390e-03,  3.7561e-03],\n",
      "          [ 3.8685e-02, -8.8764e-02, -5.3735e-02, -2.4427e-02,  1.7369e-02],\n",
      "          [ 5.5512e-02, -7.1237e-02, -6.5386e-02, -3.7746e-02,  7.1429e-03],\n",
      "          [ 3.1539e-02, -6.1858e-02, -7.4455e-02, -3.4278e-02, -9.2922e-03],\n",
      "          [ 4.5122e-02, -8.4307e-03, -2.0509e-02, -1.4743e-02,  1.0508e-03]],\n",
      "\n",
      "         [[-9.5345e-03, -2.3179e-02, -1.4264e-02, -6.7151e-03, -2.8285e-02],\n",
      "          [ 1.6202e-01, -2.8234e-02, -2.4645e-02, -1.0152e-02, -2.4914e-02],\n",
      "          [ 8.9119e-02, -2.6843e-02, -3.7465e-02, -7.5062e-03, -1.9929e-03],\n",
      "          [-4.5296e-02, -1.7844e-02, -5.1039e-03,  1.7445e-02,  1.3994e-02],\n",
      "          [-2.0449e-02, -8.8112e-04,  1.3139e-02,  1.8497e-03, -5.4345e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5179e-02,  8.3908e-03, -3.4752e-03, -6.7056e-03,  9.4571e-03],\n",
      "          [ 1.4773e-01,  1.8297e-02, -8.2707e-03, -2.6735e-03, -2.9689e-03],\n",
      "          [ 1.8945e-02, -2.4611e-02, -2.5792e-02,  5.7622e-03,  1.5490e-02],\n",
      "          [ 1.0744e-02, -2.2880e-03,  1.3852e-02, -3.0690e-03, -1.4038e-03],\n",
      "          [ 3.5738e-03, -1.7099e-02, -2.0962e-03, -5.2738e-04, -1.1953e-02]],\n",
      "\n",
      "         [[-1.8036e-02,  5.5999e-03, -4.3933e-03, -6.4853e-03,  1.1134e-02],\n",
      "          [ 8.3012e-02, -8.5719e-02, -2.3690e-02,  2.7197e-02,  1.5338e-02],\n",
      "          [ 1.6264e-02, -5.0213e-02, -2.9401e-02, -6.0407e-04,  1.5086e-02],\n",
      "          [ 1.2260e-02,  6.5707e-03, -2.8775e-03, -2.0055e-02,  4.6619e-03],\n",
      "          [ 1.4575e-02, -9.5385e-03, -2.4609e-02, -2.4521e-03,  1.0301e-03]],\n",
      "\n",
      "         [[-1.7248e-02,  7.3069e-03,  1.0429e-02, -1.4917e-02, -6.8504e-03],\n",
      "          [ 6.2874e-02, -3.2599e-02,  5.7802e-03,  1.4551e-02, -6.1276e-03],\n",
      "          [ 7.3852e-03, -6.0841e-02, -1.0494e-02,  3.6026e-03, -1.4746e-02],\n",
      "          [-1.7262e-02,  1.5815e-03, -2.3888e-02, -9.7895e-03, -7.4106e-03],\n",
      "          [ 6.9352e-03,  7.2060e-03, -1.9073e-02, -6.7136e-03,  6.1392e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7579e-02,  1.0168e-02,  4.4818e-02, -2.6664e-03, -2.2669e-02],\n",
      "          [-1.5147e-02, -3.2701e-02,  1.4564e-02, -1.2843e-02, -3.2623e-02],\n",
      "          [-3.0235e-02, -3.2706e-02, -3.4020e-02, -2.0842e-02, -3.2697e-02],\n",
      "          [-4.2032e-03, -3.4967e-03, -1.0389e-02, -9.6090e-03, -3.1508e-03],\n",
      "          [ 1.1118e-02,  8.8342e-03,  1.8196e-02,  7.5631e-03,  1.5709e-03]],\n",
      "\n",
      "         [[-9.1671e-03,  1.0798e-03, -2.4020e-02, -1.7457e-02, -7.8634e-03],\n",
      "          [-1.5174e-02,  1.8126e-02,  1.3363e-02,  7.1205e-02,  5.8289e-02],\n",
      "          [-1.0982e-02,  1.5266e-02, -2.4875e-02, -4.0705e-03, -2.4844e-02],\n",
      "          [ 2.7485e-03,  1.6571e-02, -3.2608e-02, -5.6266e-02, -3.9944e-02],\n",
      "          [-4.9014e-04,  1.9889e-02, -3.3673e-03, -2.2187e-02, -9.5482e-03]],\n",
      "\n",
      "         [[-2.6544e-02, -4.6466e-02, -1.1130e-01, -6.3725e-02,  2.4153e-02],\n",
      "          [-3.1451e-02, -4.6735e-02, -5.0069e-02,  3.6642e-02,  8.7667e-02],\n",
      "          [ 2.4192e-02,  2.9334e-02,  5.9852e-02,  4.2028e-02, -2.5984e-02],\n",
      "          [ 2.5426e-02,  1.8227e-02,  4.0526e-02, -8.6688e-03, -6.0653e-02],\n",
      "          [ 1.2664e-02,  1.5354e-02,  3.3492e-02,  1.3319e-02, -2.3908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5345e-02, -2.7450e-02, -3.7116e-02,  4.8070e-02,  1.0182e-02],\n",
      "          [-5.4621e-02, -6.3059e-02, -5.1834e-02,  6.4004e-02,  2.5790e-02],\n",
      "          [ 1.6780e-02,  1.3105e-02, -3.9535e-02, -1.2138e-03,  9.2518e-03],\n",
      "          [ 1.4997e-02,  1.2259e-02, -2.3395e-02, -2.8443e-02,  2.4942e-02],\n",
      "          [-4.0684e-03,  1.4466e-02,  6.2136e-03, -2.2554e-02, -2.0291e-03]],\n",
      "\n",
      "         [[-3.5230e-02,  8.0857e-03,  2.3528e-02, -1.0179e-02, -2.1804e-03],\n",
      "          [-3.4595e-02,  3.9871e-03,  1.3592e-02, -7.9822e-02, -5.2531e-02],\n",
      "          [-3.2725e-02,  3.4170e-02,  2.6620e-02, -2.4204e-03,  2.4924e-02],\n",
      "          [ 1.8057e-02,  4.6391e-03, -1.2008e-02,  8.8407e-03,  1.9375e-02],\n",
      "          [-2.9099e-02,  1.2933e-04, -1.7477e-02,  4.3010e-02,  6.6167e-02]],\n",
      "\n",
      "         [[ 4.6078e-02,  2.8413e-02, -2.6394e-02,  4.7513e-03, -7.6480e-02],\n",
      "          [ 7.5960e-02,  4.4307e-02, -5.8771e-02,  1.7854e-02,  9.6082e-02],\n",
      "          [ 5.8415e-02,  3.7583e-02, -6.7510e-02, -1.0312e-01, -2.3266e-02],\n",
      "          [ 4.3488e-02,  6.0671e-02,  6.2699e-02,  3.7197e-03, -5.8098e-02],\n",
      "          [ 7.3890e-05,  2.7182e-02,  4.3226e-02,  3.1200e-02, -5.9276e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5983e-02, -2.5757e-02, -2.7917e-02, -6.0154e-02, -2.1587e-02],\n",
      "          [ 5.8470e-03, -4.0597e-02, -9.7084e-02, -1.1321e-01, -4.5251e-02],\n",
      "          [-3.3056e-02, -1.7874e-02, -9.1402e-02, -1.0827e-01, -5.3423e-02],\n",
      "          [-1.4856e-02, -3.3450e-03, -2.7355e-02, -4.8538e-02, -4.1184e-02],\n",
      "          [ 9.0377e-04, -1.8180e-02, -3.1040e-02, -1.1854e-02, -2.6462e-02]],\n",
      "\n",
      "         [[ 7.2521e-02,  1.6407e-02, -1.5754e-01, -8.8864e-02, -2.1638e-02],\n",
      "          [ 9.2281e-02,  8.5642e-02, -6.8582e-02, -7.8368e-02, -9.3343e-02],\n",
      "          [ 1.1667e-01,  1.4296e-01,  1.4621e-02, -6.6599e-02, -1.8653e-01],\n",
      "          [ 4.0418e-02,  8.7898e-02,  4.2521e-02, -8.9029e-03, -1.2440e-01],\n",
      "          [ 2.0246e-02,  6.5828e-02,  9.6516e-02,  5.8696e-02, -7.2705e-02]],\n",
      "\n",
      "         [[-3.7801e-02, -1.1232e-02, -8.1927e-03,  1.2744e-02,  6.8491e-02],\n",
      "          [-4.4532e-03, -9.6229e-03, -3.2608e-02,  2.9350e-03,  3.7486e-02],\n",
      "          [ 3.3585e-02,  4.8458e-02,  2.6881e-02, -6.1178e-02, -2.1019e-02],\n",
      "          [-1.9669e-02,  6.9724e-03,  4.2018e-02, -4.3931e-02, -7.6382e-02],\n",
      "          [ 8.3337e-03,  2.5425e-03,  2.8063e-02, -3.4867e-02, -8.6687e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2673e-02, -1.5327e-02,  1.6517e-02,  3.3334e-02,  1.3038e-02],\n",
      "          [ 1.6805e-03, -1.8921e-02, -3.6130e-02,  3.2359e-02,  5.0130e-02],\n",
      "          [-1.3607e-02, -3.3703e-02, -7.9256e-02, -5.1558e-03,  6.5082e-02],\n",
      "          [-1.3499e-03,  1.9183e-02, -1.2600e-03, -1.5375e-02,  9.9117e-03],\n",
      "          [-8.6383e-03, -6.4556e-03,  4.4472e-03, -7.7968e-04,  2.6764e-02]],\n",
      "\n",
      "         [[-3.1357e-02, -6.5565e-02, -4.5553e-02,  2.9694e-02,  5.0477e-02],\n",
      "          [ 2.6388e-02, -6.5116e-03, -1.4299e-01, -2.9214e-02,  1.2134e-03],\n",
      "          [ 5.2430e-02,  6.1108e-02, -2.8583e-02, -1.0998e-01, -3.4642e-02],\n",
      "          [ 1.6018e-02,  3.1906e-02,  7.7014e-02, -1.1630e-02, -5.6960e-02],\n",
      "          [ 4.9326e-02, -1.5627e-02,  4.2784e-02,  3.7805e-02, -2.6815e-02]],\n",
      "\n",
      "         [[ 9.0381e-03,  1.6271e-03,  9.9757e-03,  2.6084e-02,  6.8623e-03],\n",
      "          [ 1.0622e-02, -6.1560e-03, -9.2547e-03,  1.8062e-02,  2.2674e-02],\n",
      "          [ 2.8991e-02,  1.2231e-04, -1.6760e-02, -1.9807e-03,  3.1453e-02],\n",
      "          [ 1.8964e-02,  2.8631e-02,  5.8559e-04, -1.0603e-02,  1.1077e-02],\n",
      "          [ 5.4998e-03, -6.3534e-03,  2.9878e-03, -2.7331e-02, -2.4437e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0352e-03, -2.0708e-02, -1.9059e-02, -2.8221e-03,  9.0732e-03],\n",
      "          [-2.2202e-02, -3.6482e-02, -3.3435e-02, -2.0294e-02, -1.1695e-02],\n",
      "          [-7.7194e-03, -3.2950e-02, -5.5740e-02, -3.5089e-02, -1.5053e-02],\n",
      "          [-1.2823e-02, -3.5408e-02, -4.2076e-02, -1.6718e-02, -1.8323e-02],\n",
      "          [-3.9433e-03,  5.0854e-03, -2.3092e-03,  1.1569e-02,  1.1675e-02]],\n",
      "\n",
      "         [[ 1.8536e-02,  2.3997e-02,  1.8607e-02, -2.1316e-03,  3.0036e-02],\n",
      "          [-9.1898e-03, -2.0234e-02, -2.0921e-02, -1.5293e-02, -4.1515e-03],\n",
      "          [-2.5399e-02, -3.6147e-02,  1.1215e-02, -1.3978e-02,  1.0484e-02],\n",
      "          [-1.7011e-03, -1.7085e-02,  1.9866e-02,  6.1436e-03,  4.9555e-03],\n",
      "          [ 1.0626e-02,  1.2917e-02,  4.2516e-02,  1.5874e-02,  1.7050e-02]],\n",
      "\n",
      "         [[-4.0153e-03,  1.6083e-02,  8.7844e-03, -9.1274e-03,  2.2305e-02],\n",
      "          [-2.0949e-02, -3.9927e-03, -3.2194e-02, -2.1123e-02, -1.3385e-03],\n",
      "          [-4.2372e-03,  1.4911e-02,  3.8126e-03, -5.2412e-03,  9.8842e-03],\n",
      "          [ 1.2249e-02,  3.7495e-03, -3.4932e-03,  6.0049e-03,  1.4841e-02],\n",
      "          [ 1.3200e-02, -1.9996e-03,  2.0933e-02,  1.6309e-04, -8.3707e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4706e-03, -3.2926e-02, -1.5733e-02, -1.7831e-02,  2.1256e-03],\n",
      "          [-5.4066e-02, -5.4719e-02, -4.5444e-02, -5.6256e-02, -3.6743e-02],\n",
      "          [ 2.8305e-02,  2.9538e-02,  4.4844e-02,  2.2081e-02,  3.5385e-02],\n",
      "          [ 1.6821e-02,  1.6557e-02,  5.4560e-02,  1.7084e-02,  2.3373e-02],\n",
      "          [-4.0657e-03, -8.0451e-03,  4.4215e-04,  7.5198e-03,  1.0919e-02]],\n",
      "\n",
      "         [[ 2.0678e-02,  2.0736e-02,  7.6578e-02,  2.9091e-02,  4.1559e-02],\n",
      "          [-1.0118e-03,  5.5359e-02,  1.3228e-01,  6.7964e-02,  4.1530e-02],\n",
      "          [-3.9346e-03,  3.5696e-02,  1.2877e-01,  6.1861e-02,  2.9380e-02],\n",
      "          [ 2.5981e-02,  3.8598e-02,  1.3250e-01,  3.2665e-02, -1.8039e-02],\n",
      "          [-1.9937e-02, -1.3913e-02, -1.0549e-02, -1.3653e-02, -2.4947e-03]],\n",
      "\n",
      "         [[ 7.0426e-02,  2.1494e-02, -9.1289e-03, -9.1144e-03, -5.7207e-03],\n",
      "          [ 3.0881e-02, -1.0100e-02, -5.8352e-02, -3.8790e-02, -2.0214e-02],\n",
      "          [-7.5705e-03, -4.3871e-02, -8.5624e-02, -5.4874e-02, -1.8760e-02],\n",
      "          [-5.6932e-03, -4.2488e-02, -7.0337e-02, -3.9515e-02,  2.8042e-03],\n",
      "          [ 4.9093e-02,  8.0856e-03, -2.0497e-02,  1.7022e-02,  2.4330e-02]]]],\n",
      "       requires_grad=True)\n",
      "3 features.3.bias Parameter containing:\n",
      "tensor([-1.0928e-01, -1.7263e-01, -5.1698e-02, -6.5495e-02, -3.9439e-02,\n",
      "         1.7420e-01, -1.8464e-01,  9.5525e-02, -2.5099e-02, -3.0075e-02,\n",
      "         1.3654e-01, -3.2269e-01, -1.4834e-01,  1.2790e-01,  4.0678e-03,\n",
      "        -5.7279e-02, -2.1440e-03,  2.0314e-01,  3.3098e-01,  7.3128e-02,\n",
      "         4.9798e-01, -4.4765e-02, -8.2151e-02,  1.4895e-02, -4.6373e-02,\n",
      "         5.7510e-02,  1.9020e-02,  7.4533e-04, -1.8182e-01, -1.2202e-04,\n",
      "        -1.3162e-01, -1.2743e-01,  5.9956e-03, -4.2740e-01,  1.1648e-01,\n",
      "        -1.6375e-01, -6.0307e-02, -2.3113e-01,  2.4188e-01, -7.8616e-02,\n",
      "         2.0777e-02, -2.5044e-02, -4.4685e-02,  2.8326e-02, -1.7459e-01,\n",
      "         7.1566e-02, -5.7368e-02,  1.2070e-01, -5.8133e-02, -1.7347e-01,\n",
      "        -1.2782e-01,  5.3739e-02,  4.5314e-02,  9.4975e-02,  1.0401e-02,\n",
      "         1.3877e-01, -1.3664e-01,  2.4293e-01,  1.4512e-01,  4.8102e-01,\n",
      "        -1.1793e-01, -1.5927e-01,  1.6019e-01,  2.2559e-01,  9.6043e-02,\n",
      "         2.9943e-02, -1.7576e-01, -9.5031e-02,  2.3446e-01, -2.4519e-01,\n",
      "         1.0253e-01, -2.4316e-01, -5.6964e-02, -2.7844e-02, -3.4611e-01,\n",
      "         4.0740e-02, -2.3085e-01,  1.9122e-01,  1.6288e-01,  2.9599e-01,\n",
      "        -1.3699e-01,  5.2276e-03, -1.6603e-01, -7.7020e-02, -1.1686e-01,\n",
      "         6.8327e-02, -9.8369e-02, -9.1281e-02, -1.6490e-01,  6.2494e-02,\n",
      "         1.0231e-01, -5.7519e-03, -1.7242e-01, -8.5797e-03, -1.2002e-01,\n",
      "        -1.8632e-01, -5.3833e-02, -6.7391e-02, -1.4795e-01,  2.6208e-02,\n",
      "         3.9989e-02, -2.1992e-01, -1.4985e-01, -8.3122e-02, -6.7938e-02,\n",
      "        -7.8998e-02, -4.2145e-02,  3.7165e-01, -1.8347e-01,  6.1246e-02,\n",
      "        -4.7721e-01, -2.1703e-01, -7.0511e-02, -9.9998e-02, -4.4748e-02,\n",
      "         8.6560e-02, -1.3605e-01, -1.8263e-01, -3.7893e-02, -2.9278e-01,\n",
      "        -1.3911e-01,  1.4130e-01,  2.9491e-01,  2.7607e-01, -4.4584e-02,\n",
      "         3.6733e-01,  8.7795e-02, -2.0914e-02,  2.0941e-01,  4.9935e-01,\n",
      "         1.4991e-01, -1.3268e-01,  2.1515e-01,  2.3250e-01,  1.4488e-01,\n",
      "        -8.2328e-02, -3.2715e-02, -1.2761e-01,  1.1177e-01,  3.8759e-01,\n",
      "        -3.7940e-02, -1.7950e-01,  3.1519e-01, -4.0012e-02,  3.2606e-01,\n",
      "         1.0944e-02, -4.2019e-01, -1.9330e-01,  4.6443e-02,  1.4548e-02,\n",
      "         4.1791e-02,  1.4871e-01, -1.5567e-01, -1.6159e-01,  4.9127e-01,\n",
      "        -1.4576e-01,  1.3040e-01, -3.2479e-02, -3.3374e-02, -3.0722e-01,\n",
      "         3.0348e-01, -8.2917e-02,  1.5031e-01, -2.1193e-02,  1.7708e-01,\n",
      "         2.0579e-01,  1.0637e-01, -1.4460e-01, -1.6046e-01, -2.6753e-02,\n",
      "        -6.7287e-02,  4.8736e-01,  1.7410e-01,  1.8411e-01, -8.9367e-02,\n",
      "         1.4409e-01,  5.3045e-02, -1.3101e-01, -8.4564e-02, -3.6975e-02,\n",
      "        -2.3806e-01, -8.0580e-02, -9.7469e-02,  1.4895e-01, -3.0727e-03,\n",
      "         2.8690e-01,  9.3942e-02,  1.2006e-01, -1.2438e-01,  7.2421e-02,\n",
      "         1.3842e-02,  7.2982e-02], requires_grad=True)\n",
      "4 features.6.weight Parameter containing:\n",
      "tensor([[[[ 2.4858e-02,  1.3116e-02,  2.8198e-02],\n",
      "          [ 4.2541e-02,  5.7339e-02, -6.0905e-03],\n",
      "          [-4.1912e-03,  9.3096e-03, -1.5442e-02]],\n",
      "\n",
      "         [[-3.8954e-03, -7.8586e-02, -5.1808e-02],\n",
      "          [ 2.6484e-02, -4.9877e-02, -1.7763e-03],\n",
      "          [ 8.2902e-03, -4.9339e-02,  3.1145e-02]],\n",
      "\n",
      "         [[ 1.6455e-02, -1.2150e-02,  1.7428e-02],\n",
      "          [ 5.2012e-02, -6.7141e-03,  2.7325e-02],\n",
      "          [ 7.5568e-03, -4.2402e-02, -2.7909e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7289e-04,  2.4099e-02,  3.6948e-02],\n",
      "          [-2.4145e-02, -3.5276e-02,  3.6910e-03],\n",
      "          [ 1.9541e-02, -3.0342e-02, -3.5262e-02]],\n",
      "\n",
      "         [[ 1.3239e-02, -1.8624e-02, -5.3330e-02],\n",
      "          [ 1.7639e-04, -1.4714e-02, -2.2829e-02],\n",
      "          [-6.7702e-03,  2.3287e-02,  1.3873e-02]],\n",
      "\n",
      "         [[ 3.0512e-02,  7.5860e-03,  4.9459e-04],\n",
      "          [-4.5703e-03, -1.2827e-02, -6.5061e-03],\n",
      "          [-9.8111e-03, -1.5570e-02,  1.9379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3660e-02, -3.9180e-02,  2.0014e-02],\n",
      "          [ 5.7389e-02,  1.1934e-02,  2.3058e-02],\n",
      "          [-2.2237e-02, -1.8879e-02, -2.0941e-02]],\n",
      "\n",
      "         [[-1.3402e-02,  1.9384e-02,  2.0018e-02],\n",
      "          [ 2.2285e-03, -1.5328e-02, -2.0604e-02],\n",
      "          [ 5.2206e-02, -4.0713e-02, -1.6011e-02]],\n",
      "\n",
      "         [[ 8.2728e-03, -1.2311e-02, -2.6974e-02],\n",
      "          [ 2.5519e-03, -5.6930e-03, -5.1476e-02],\n",
      "          [-2.8822e-02, -8.5134e-02, -6.5895e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1531e-02,  2.4226e-02,  6.0344e-04],\n",
      "          [-3.3641e-02,  7.7504e-02, -1.8122e-02],\n",
      "          [ 2.2435e-02,  6.3408e-02, -1.0774e-03]],\n",
      "\n",
      "         [[-1.6893e-02,  5.7512e-03,  3.7639e-02],\n",
      "          [-1.6503e-02, -3.2492e-03,  3.6293e-02],\n",
      "          [ 3.2918e-02, -1.2321e-02,  1.4753e-03]],\n",
      "\n",
      "         [[ 5.8365e-02,  6.4994e-02,  6.6423e-02],\n",
      "          [-1.3995e-02, -2.4027e-02, -1.2127e-02],\n",
      "          [ 2.6365e-03, -1.4931e-02, -7.9207e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0889e-03,  9.6816e-03, -1.2593e-02],\n",
      "          [ 1.1684e-02,  4.7408e-02,  4.9439e-02],\n",
      "          [-1.1663e-02,  7.7298e-02,  2.3240e-02]],\n",
      "\n",
      "         [[ 9.5861e-03, -3.5039e-02, -1.5836e-02],\n",
      "          [-2.2685e-02,  1.6363e-02,  1.8725e-02],\n",
      "          [-1.7577e-02, -5.9963e-03, -1.2350e-02]],\n",
      "\n",
      "         [[-3.9020e-03, -5.0362e-03,  2.8650e-03],\n",
      "          [ 2.3688e-02,  3.0239e-03, -5.0350e-02],\n",
      "          [-3.0330e-02, -2.0917e-02, -9.9929e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3766e-02, -4.8649e-03,  3.4593e-03],\n",
      "          [-1.7299e-03,  9.8713e-03,  3.1695e-03],\n",
      "          [-1.5713e-02,  2.4070e-02,  4.3523e-02]],\n",
      "\n",
      "         [[ 1.7398e-02,  3.9648e-02,  5.0599e-02],\n",
      "          [-1.8082e-02,  2.3186e-02,  7.5082e-02],\n",
      "          [-1.4652e-02, -1.4806e-03,  2.4491e-02]],\n",
      "\n",
      "         [[-3.6486e-03,  1.6976e-02,  9.5258e-03],\n",
      "          [ 8.3009e-03,  3.0063e-03, -3.5994e-03],\n",
      "          [-2.0521e-04, -9.6109e-04, -7.6914e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1159e-02,  3.1025e-02, -5.1508e-04],\n",
      "          [-2.0021e-02, -9.5897e-03,  2.7262e-02],\n",
      "          [-9.7968e-03, -3.9145e-02,  9.2344e-03]],\n",
      "\n",
      "         [[-2.2890e-02, -6.2061e-03, -1.8220e-02],\n",
      "          [ 2.6104e-02,  1.8208e-02, -3.5678e-02],\n",
      "          [-1.9037e-02, -2.5568e-02, -3.2400e-03]],\n",
      "\n",
      "         [[ 4.5357e-04,  1.1460e-02,  3.0362e-02],\n",
      "          [ 2.1339e-02,  1.1392e-02,  1.3384e-02],\n",
      "          [ 2.2492e-02, -1.0258e-02, -5.8449e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7361e-02,  1.4307e-02,  1.8851e-02],\n",
      "          [ 3.9169e-02, -4.1835e-02, -1.2617e-03],\n",
      "          [-2.4972e-02, -6.0201e-02,  1.1093e-02]],\n",
      "\n",
      "         [[ 1.3269e-02,  2.8252e-02, -2.0582e-02],\n",
      "          [ 1.2612e-02,  5.3777e-02, -2.9175e-02],\n",
      "          [ 4.3714e-02,  1.5523e-02, -3.4617e-02]],\n",
      "\n",
      "         [[-1.4312e-02, -1.1627e-02, -8.0607e-03],\n",
      "          [-1.7464e-02,  9.4876e-03, -3.3993e-04],\n",
      "          [-4.5948e-03,  2.4349e-02,  2.9515e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3024e-02,  3.7754e-02, -7.9412e-03],\n",
      "          [ 2.3338e-02, -3.2373e-02, -4.1358e-02],\n",
      "          [ 6.4814e-02,  2.6370e-02,  4.9119e-02]],\n",
      "\n",
      "         [[ 4.7991e-02, -2.4855e-02,  1.2162e-02],\n",
      "          [-2.7339e-02,  3.9421e-02, -1.8773e-02],\n",
      "          [-5.8830e-02,  2.6058e-02,  1.4781e-03]],\n",
      "\n",
      "         [[ 8.6110e-03, -2.6908e-02,  1.1525e-02],\n",
      "          [ 5.6151e-02, -1.3285e-02, -7.1971e-03],\n",
      "          [ 1.1242e-03, -4.7446e-02, -3.6017e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5633e-02, -8.5117e-03,  6.2245e-02],\n",
      "          [ 1.0972e-02,  1.9737e-02,  4.8234e-02],\n",
      "          [-1.1555e-02,  4.3559e-03,  5.2946e-02]],\n",
      "\n",
      "         [[-1.0731e-03,  2.2912e-02,  2.2005e-02],\n",
      "          [ 1.3288e-02,  4.9365e-02,  1.2220e-02],\n",
      "          [ 1.0511e-02,  1.7318e-02, -1.8007e-02]],\n",
      "\n",
      "         [[-2.6693e-02, -1.8063e-02, -2.4829e-02],\n",
      "          [-3.3943e-02, -1.4893e-03, -1.1168e-02],\n",
      "          [-1.3225e-02, -4.6098e-03,  3.0331e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0866e-03, -2.5078e-02, -4.7683e-02],\n",
      "          [ 2.4006e-02,  5.2576e-02, -2.1802e-02],\n",
      "          [ 2.5606e-02,  1.1889e-02, -2.4519e-03]],\n",
      "\n",
      "         [[ 2.5286e-02, -2.8539e-02,  8.4982e-03],\n",
      "          [ 6.8764e-03, -8.9434e-03,  3.4527e-03],\n",
      "          [ 2.7720e-02,  1.2911e-02,  1.2079e-02]],\n",
      "\n",
      "         [[ 2.8175e-02,  1.3563e-02,  6.9976e-02],\n",
      "          [ 2.7799e-02, -3.6929e-02,  1.0927e-01],\n",
      "          [ 2.3212e-02, -3.4578e-02, -4.8821e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3232e-04,  1.7463e-02, -9.6818e-03],\n",
      "          [ 9.2093e-03,  1.5052e-02,  8.6647e-03],\n",
      "          [-1.8870e-02, -2.1472e-02, -1.5119e-02]],\n",
      "\n",
      "         [[ 4.3916e-02, -5.5188e-05, -7.7297e-03],\n",
      "          [-8.0442e-03, -3.4422e-02, -2.2207e-02],\n",
      "          [-1.4105e-02, -2.7909e-02, -2.4631e-02]],\n",
      "\n",
      "         [[-2.6292e-02,  1.1666e-02, -1.6261e-02],\n",
      "          [-5.7774e-02, -5.8361e-02, -4.8310e-02],\n",
      "          [-4.1695e-02, -6.6255e-02, -5.7636e-02]]]], requires_grad=True)\n",
      "5 features.6.bias Parameter containing:\n",
      "tensor([ 2.5296e-02,  1.1945e-01, -3.3357e-01,  1.1266e-01, -1.1582e-01,\n",
      "        -5.9723e-02,  1.1421e-01, -9.5083e-02,  3.1485e-02, -1.1093e-02,\n",
      "        -4.9384e-02,  9.1009e-02, -5.2086e-02,  3.6598e-02, -1.2018e-01,\n",
      "        -1.3416e-01, -5.0457e-03, -1.4378e-03, -7.6294e-02, -4.9133e-02,\n",
      "        -1.2550e-01,  2.3369e-01, -8.1535e-02,  2.4502e-02, -1.1238e-02,\n",
      "         1.3240e-01,  2.5781e-01, -2.4450e-02,  7.3169e-02,  2.0816e-01,\n",
      "         5.9903e-02, -1.1075e-02,  7.0557e-02,  5.3707e-03,  1.3942e-02,\n",
      "        -6.9005e-02,  9.5581e-02,  8.2127e-02, -8.9249e-02,  2.3552e-02,\n",
      "         2.0885e-02,  2.0952e-01,  5.7000e-02,  1.0061e-01, -1.5167e-01,\n",
      "         5.1431e-02,  6.0977e-02,  1.6120e-01,  4.6385e-02, -2.9361e-01,\n",
      "        -1.9220e-01, -3.3040e-02, -2.2844e-01,  5.2254e-02, -4.1985e-02,\n",
      "        -2.2856e-01, -2.2374e-01, -1.0398e-01, -3.9473e-02,  2.3086e-02,\n",
      "         8.5222e-02, -3.7522e-03,  9.9965e-02,  2.2243e-01,  1.4045e-01,\n",
      "        -8.3344e-02, -1.5321e-02,  8.4639e-04,  2.0019e-02, -1.4662e-01,\n",
      "        -5.2505e-02, -8.1782e-02,  3.8130e-01, -3.4659e-02, -4.2694e-02,\n",
      "         1.8965e-02,  3.0156e-01,  1.2823e-01,  1.3799e-01,  1.2063e-01,\n",
      "        -3.4695e-02,  1.0009e-01, -7.9640e-02, -7.5065e-02,  1.0233e-01,\n",
      "         3.2208e-01,  2.1217e-01,  3.0716e-01, -8.1736e-03,  1.3200e-01,\n",
      "        -6.8293e-02,  1.4088e-01, -6.3016e-02, -8.2268e-02,  3.3019e-02,\n",
      "        -1.8908e-01, -1.6634e-02, -1.8369e-01,  2.0020e-01,  6.9814e-02,\n",
      "        -1.3038e-02,  1.3110e-01,  1.9347e-01,  3.4634e-01, -4.2031e-02,\n",
      "        -1.6328e-02,  1.1963e-01, -6.8291e-02, -1.5022e-01,  9.9076e-03,\n",
      "        -3.0987e-01,  9.0031e-02, -8.1147e-02, -5.2415e-02, -9.0178e-02,\n",
      "         5.0669e-02, -2.6872e-02,  1.4879e-01, -6.0823e-02, -7.0688e-02,\n",
      "        -3.4375e-02,  1.9965e-01,  5.5266e-01, -7.1537e-02, -9.4906e-03,\n",
      "         1.0071e-01, -9.5097e-03, -2.5680e-02,  9.7761e-02,  1.1309e-02,\n",
      "         5.2728e-01,  2.7153e-01,  1.3556e-01,  2.2964e-01, -1.2627e-01,\n",
      "         1.3784e-02, -2.2356e-02, -1.8921e-01, -4.5453e-02, -2.9798e-02,\n",
      "         4.6675e-02, -5.1737e-02, -1.7543e-01, -3.4338e-01, -5.7257e-03,\n",
      "        -2.3548e-01,  5.3668e-02,  3.4909e-01, -2.3416e-01, -1.1250e-01,\n",
      "         3.1410e-02, -9.6694e-02, -1.6565e-01, -2.2653e-03, -2.5939e-01,\n",
      "         5.0781e-02,  8.9765e-02, -1.0748e-02,  1.2842e-01,  3.5524e-02,\n",
      "         3.3868e-02, -5.5422e-03, -9.5143e-02, -3.0961e-02,  3.2034e-02,\n",
      "         5.2717e-02,  1.2630e-01,  1.5936e-01,  3.5871e-02,  3.5311e-02,\n",
      "         3.6975e-01,  1.7943e-02, -2.2763e-02, -9.5617e-02,  1.7291e-01,\n",
      "         5.1715e-02,  1.5322e-01, -1.2241e-02,  2.5096e-01, -1.6052e-02,\n",
      "         2.2399e-02, -2.8640e-02,  1.1971e-01, -2.5529e-02, -4.1908e-02,\n",
      "         2.1012e-01, -1.3480e-01, -1.6478e-01, -2.5691e-02, -1.2916e-01,\n",
      "        -1.6463e-01,  5.3876e-02,  1.1469e-01, -1.1934e-01, -5.9146e-02,\n",
      "        -1.5055e-01, -2.7029e-02,  1.0714e-01, -8.8103e-02,  1.1475e-01,\n",
      "         1.7447e-01,  1.5797e-01,  5.2465e-02, -2.8796e-02,  2.4430e-01,\n",
      "         1.4584e-01,  1.1052e-02,  2.1882e-01,  3.9874e-01,  3.2079e-01,\n",
      "        -8.7249e-02, -7.7314e-02,  5.5055e-02, -7.4239e-02,  2.9941e-01,\n",
      "        -1.1196e-01,  2.0385e-02, -1.6533e-01, -8.4008e-02,  9.1928e-02,\n",
      "        -1.6281e-02, -1.3456e-02,  3.4111e-02, -1.5228e-01,  7.9972e-02,\n",
      "        -1.5468e-02,  9.0530e-02, -1.2425e-01,  4.0860e-02,  6.5097e-02,\n",
      "        -3.7378e-02, -2.5349e-02,  2.8863e-01, -1.7786e-01,  4.5379e-02,\n",
      "         8.0375e-02, -1.1857e-01,  1.2685e-01,  1.3253e-02,  4.4984e-03,\n",
      "         8.3759e-02,  1.5047e-01, -7.4856e-02, -5.1144e-02, -1.5849e-01,\n",
      "         1.1111e-01,  2.0428e-02,  1.9939e-02,  2.4965e-01,  2.1343e-01,\n",
      "         1.1922e-01,  1.5213e-01,  1.0119e-01, -2.0210e-02,  1.8933e-02,\n",
      "        -1.5583e-01,  2.6090e-01, -2.9025e-02,  6.5378e-02,  9.3637e-02,\n",
      "        -3.3498e-02, -1.0445e-01,  1.4307e-01,  8.0963e-02, -1.6300e-01,\n",
      "         1.8334e-01, -6.3191e-02,  3.4443e-02,  2.2093e-02, -1.0206e-01,\n",
      "         8.7264e-02,  1.8751e-02, -1.5014e-01,  2.3940e-01,  2.2395e-01,\n",
      "        -2.4017e-02,  2.3110e-01, -1.0960e-01, -1.6953e-01, -3.6366e-02,\n",
      "        -5.0821e-02,  7.6745e-02,  2.0642e-01,  1.4263e-03,  1.1277e-01,\n",
      "        -2.0354e-01,  8.0649e-02,  2.0421e-01,  3.6917e-01,  1.2266e-01,\n",
      "        -2.3815e-02, -7.3110e-02, -1.5845e-02,  1.2772e-01, -5.7867e-02,\n",
      "         2.8672e-01, -4.2656e-03, -2.1363e-05,  2.1605e-01,  1.5520e-01,\n",
      "        -1.6205e-02, -9.7204e-02, -1.0046e-01, -1.9993e-02, -1.5217e-01,\n",
      "        -5.9612e-02,  3.1248e-03, -3.4129e-01,  1.6236e-01,  1.7470e-01,\n",
      "         2.0988e-01, -6.3615e-02,  5.4698e-02, -2.4567e-01,  1.2553e-01,\n",
      "        -4.4876e-02, -5.9439e-02,  2.9393e-02,  1.5098e-01, -4.0008e-02,\n",
      "         1.1208e-01, -1.5519e-01,  5.0468e-01, -4.7305e-02, -7.5279e-02,\n",
      "         4.2626e-02, -1.3383e-01, -4.2012e-01,  3.8201e-01,  8.9413e-02,\n",
      "         5.3007e-02,  5.8240e-02,  4.2868e-02,  2.5090e-02,  1.9713e-01,\n",
      "         1.0120e-01, -1.1193e-01, -2.8088e-02,  3.5423e-01,  2.3811e-02,\n",
      "         1.2284e-01, -1.2416e-01,  3.0930e-02, -1.1544e-01, -2.8152e-02,\n",
      "         2.3655e-02,  1.5912e-02,  1.0024e-01,  1.1166e-01,  8.4823e-03,\n",
      "        -1.3086e-01,  9.2488e-02, -5.3630e-03,  8.9322e-02,  5.3354e-02,\n",
      "         6.6519e-02,  3.5378e-02,  4.4817e-02, -8.7586e-02,  1.3602e-01,\n",
      "         1.8784e-01, -3.7431e-02,  3.4593e-02,  3.8587e-02, -1.9506e-01,\n",
      "        -8.4326e-02, -6.7575e-02, -1.1365e-02,  1.0826e-01, -1.0933e-01,\n",
      "        -4.5308e-02,  2.1318e-02,  1.2107e-01,  1.1220e-01, -9.5198e-02,\n",
      "         5.0955e-01, -3.2508e-03,  5.4857e-02,  6.7155e-02,  1.0905e-01,\n",
      "         1.8573e-02, -2.9313e-02,  1.1019e-02, -1.1489e-02],\n",
      "       requires_grad=True)\n",
      "6 features.8.weight Parameter containing:\n",
      "tensor([[[[-0.0020, -0.0081, -0.0114],\n",
      "          [-0.0193,  0.0007,  0.0114],\n",
      "          [-0.0541, -0.0012, -0.0244]],\n",
      "\n",
      "         [[ 0.0350,  0.0133,  0.0260],\n",
      "          [-0.0282, -0.0062, -0.0269],\n",
      "          [ 0.0035,  0.0181,  0.0147]],\n",
      "\n",
      "         [[-0.0572, -0.0474,  0.0019],\n",
      "          [-0.0402, -0.0462, -0.0257],\n",
      "          [-0.0515, -0.0490,  0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0184, -0.0234,  0.0097],\n",
      "          [-0.0443, -0.0076, -0.0178],\n",
      "          [-0.0518, -0.0351, -0.0455]],\n",
      "\n",
      "         [[-0.0037, -0.0011, -0.0447],\n",
      "          [-0.0524, -0.0318, -0.0524],\n",
      "          [-0.0031, -0.0111, -0.0443]],\n",
      "\n",
      "         [[-0.0199, -0.0015,  0.0159],\n",
      "          [ 0.0051, -0.0149, -0.0237],\n",
      "          [ 0.0259,  0.0332,  0.0081]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0210,  0.0214,  0.0528],\n",
      "          [-0.0056,  0.0240,  0.0338],\n",
      "          [-0.0091,  0.0343,  0.0236]],\n",
      "\n",
      "         [[-0.0239, -0.0183, -0.0083],\n",
      "          [ 0.0316,  0.0136,  0.0453],\n",
      "          [-0.0357,  0.0247,  0.0101]],\n",
      "\n",
      "         [[ 0.0013,  0.0397,  0.0254],\n",
      "          [ 0.0308,  0.0113, -0.0031],\n",
      "          [-0.0280,  0.0023, -0.0184]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195, -0.0042, -0.0179],\n",
      "          [ 0.0192,  0.0265,  0.0026],\n",
      "          [ 0.0137, -0.0102,  0.0086]],\n",
      "\n",
      "         [[ 0.0275,  0.0256,  0.0252],\n",
      "          [-0.0102, -0.0263, -0.0122],\n",
      "          [-0.0340,  0.0067,  0.0385]],\n",
      "\n",
      "         [[-0.0022,  0.0217,  0.0112],\n",
      "          [ 0.0122, -0.0210,  0.0075],\n",
      "          [-0.0028, -0.0052, -0.0128]]],\n",
      "\n",
      "\n",
      "        [[[-0.0329, -0.0248, -0.0185],\n",
      "          [-0.0054,  0.0061,  0.0126],\n",
      "          [ 0.0478,  0.0188,  0.0413]],\n",
      "\n",
      "         [[-0.0074, -0.0016,  0.0026],\n",
      "          [ 0.0047, -0.0048,  0.0078],\n",
      "          [-0.0068,  0.0028,  0.0143]],\n",
      "\n",
      "         [[ 0.0005, -0.0228, -0.0027],\n",
      "          [-0.0152, -0.0249,  0.0235],\n",
      "          [ 0.0053, -0.0205,  0.0647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0352, -0.0149,  0.0171],\n",
      "          [-0.0023, -0.0084, -0.0010],\n",
      "          [-0.0209,  0.0037, -0.0223]],\n",
      "\n",
      "         [[-0.0042, -0.0047, -0.0100],\n",
      "          [-0.0069, -0.0281, -0.0387],\n",
      "          [ 0.0048,  0.0333,  0.0114]],\n",
      "\n",
      "         [[-0.0421,  0.0002, -0.0347],\n",
      "          [-0.0001,  0.0014, -0.0092],\n",
      "          [ 0.0719,  0.0502,  0.0573]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0410,  0.0385,  0.0163],\n",
      "          [ 0.0073, -0.0176, -0.0462],\n",
      "          [-0.0201, -0.0263, -0.0473]],\n",
      "\n",
      "         [[ 0.0129,  0.0227,  0.0252],\n",
      "          [ 0.0145,  0.0254,  0.0300],\n",
      "          [-0.0025,  0.0151,  0.0112]],\n",
      "\n",
      "         [[-0.0199, -0.0113, -0.0104],\n",
      "          [ 0.0127,  0.0129,  0.0073],\n",
      "          [ 0.0161,  0.0055, -0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0302,  0.0051, -0.0012],\n",
      "          [ 0.0208,  0.0003, -0.0187],\n",
      "          [-0.0144, -0.0357, -0.0175]],\n",
      "\n",
      "         [[ 0.0599,  0.0085,  0.0075],\n",
      "          [ 0.0610,  0.0170, -0.0337],\n",
      "          [ 0.0119,  0.0251, -0.0149]],\n",
      "\n",
      "         [[-0.0455, -0.0504, -0.0410],\n",
      "          [-0.0200, -0.0281, -0.0193],\n",
      "          [-0.0178, -0.0225, -0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0077, -0.0249,  0.0156],\n",
      "          [-0.0249,  0.0043,  0.0494],\n",
      "          [ 0.0045,  0.0455,  0.0455]],\n",
      "\n",
      "         [[ 0.0105,  0.0247, -0.0057],\n",
      "          [ 0.0461,  0.0305,  0.0349],\n",
      "          [-0.0354,  0.0422, -0.0025]],\n",
      "\n",
      "         [[ 0.0247,  0.0364,  0.0006],\n",
      "          [-0.0022, -0.0204, -0.0010],\n",
      "          [-0.0189, -0.0207, -0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0123, -0.0342, -0.0004],\n",
      "          [-0.0067, -0.0245, -0.0082],\n",
      "          [-0.0122,  0.0133,  0.0139]],\n",
      "\n",
      "         [[ 0.0098,  0.0259,  0.0180],\n",
      "          [ 0.0376,  0.0472,  0.0034],\n",
      "          [ 0.0239, -0.0019, -0.0128]],\n",
      "\n",
      "         [[ 0.0087,  0.0292, -0.0075],\n",
      "          [ 0.0031, -0.0118, -0.0158],\n",
      "          [-0.0128, -0.0524,  0.0036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0005,  0.0481,  0.0279],\n",
      "          [ 0.0006, -0.0294, -0.0090],\n",
      "          [ 0.0095,  0.0028,  0.0157]],\n",
      "\n",
      "         [[ 0.0166,  0.0328,  0.0182],\n",
      "          [-0.0055,  0.0275,  0.0119],\n",
      "          [-0.0541, -0.0190, -0.0386]],\n",
      "\n",
      "         [[-0.0386, -0.0353,  0.0143],\n",
      "          [-0.0577, -0.0483,  0.0289],\n",
      "          [-0.0361,  0.0032,  0.0618]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133,  0.0259,  0.0499],\n",
      "          [ 0.0033, -0.0500,  0.0009],\n",
      "          [ 0.0153,  0.0184,  0.0001]],\n",
      "\n",
      "         [[-0.0324, -0.0163,  0.0237],\n",
      "          [-0.0012, -0.0137,  0.0037],\n",
      "          [-0.0236,  0.0041,  0.0363]],\n",
      "\n",
      "         [[-0.0293, -0.0176, -0.0268],\n",
      "          [-0.0341,  0.0460, -0.0113],\n",
      "          [ 0.0003,  0.0701,  0.0068]]]], requires_grad=True)\n",
      "7 features.8.bias Parameter containing:\n",
      "tensor([-6.2908e-02,  1.2599e-01,  2.9910e-01,  1.1226e-01,  2.8529e-01,\n",
      "         1.2800e-01,  1.8281e-01, -3.0966e-02,  5.4521e-01,  1.5652e-01,\n",
      "        -1.3417e-01, -1.7108e-01,  2.7399e-01,  2.2774e-01,  2.6715e-01,\n",
      "         2.6192e-01,  4.5637e-02, -1.4264e+00,  6.0950e-01,  8.2353e-02,\n",
      "         9.6382e-02,  1.5679e-01, -2.9053e-01,  1.2642e-01,  2.0995e-01,\n",
      "         7.2459e-02, -2.7236e-04, -2.2086e-01,  1.1173e-01,  4.8032e-01,\n",
      "         3.5515e-02, -2.7491e-01, -5.0275e-01,  6.9615e-04, -1.2266e-01,\n",
      "         1.4878e-01, -8.2103e-03,  1.3206e-01,  2.9920e-01, -1.6474e-01,\n",
      "         3.2465e-01,  5.3489e-01,  2.4496e-01,  5.9936e-01,  3.3782e-02,\n",
      "         6.6390e-02,  4.8976e-01,  4.2106e-01,  6.3466e-01, -9.4680e-02,\n",
      "        -7.8501e-02,  2.5697e-01,  7.6671e-02, -2.3927e-01,  1.7104e-01,\n",
      "         4.1678e-01,  2.6976e-01, -4.6004e-01, -8.4528e-02,  2.7783e-01,\n",
      "         2.6750e-01,  3.3215e-01,  5.0680e-02, -8.6297e-02, -2.1007e-01,\n",
      "        -5.2222e-02, -4.1103e-02, -1.3916e-01, -3.0490e-01,  3.0167e-01,\n",
      "         2.3581e-01, -3.8736e-01, -6.0125e-02,  9.0375e-01, -1.4004e-01,\n",
      "         5.3197e-01,  2.3184e-01,  2.0689e-01,  2.3384e-01, -3.6393e-01,\n",
      "         2.2036e-01, -5.4082e-01, -6.4925e-01,  9.8469e-02,  3.4030e-01,\n",
      "         2.8475e-01, -1.1668e-01, -1.4938e-01,  2.6740e-01, -1.4695e-01,\n",
      "         5.2876e-02,  2.9656e-01,  1.4841e-02,  1.7320e-01,  1.5211e-01,\n",
      "         1.1128e-02, -2.4402e-02, -9.2617e-02, -5.4720e-02,  1.7771e-01,\n",
      "         7.6462e-03, -1.5598e-02, -1.9971e-02,  3.0060e-02,  3.4280e-01,\n",
      "         1.8484e-01, -1.8930e-01,  1.1917e-01,  4.3845e-02,  2.4088e-01,\n",
      "        -1.2948e-01,  2.8659e-01, -3.3983e-01,  1.7242e-01, -1.3951e-02,\n",
      "        -3.3238e-02, -2.1374e-01, -3.9050e-01,  6.9830e-01,  2.8698e-02,\n",
      "         7.4814e-02,  1.5877e-01,  1.6203e-01,  3.8714e-02,  1.4981e-01,\n",
      "        -7.0573e-02,  2.8210e-01,  3.0193e-01, -4.7925e-01,  9.4767e-02,\n",
      "        -2.5825e-01, -3.0498e-01,  3.7155e-01,  4.2541e-02,  2.2962e-01,\n",
      "         7.1776e-02,  1.0767e-01,  2.1197e-01,  2.8018e-01,  3.7508e-01,\n",
      "        -1.2975e-01,  2.2353e-01,  1.5561e-02,  2.9895e-01,  5.8271e-01,\n",
      "         4.4767e-01,  3.1934e-01,  1.5509e-01,  1.6081e-01,  2.4762e-01,\n",
      "        -6.7093e-01,  2.4884e-01,  1.4737e-01,  9.3295e-02,  2.3992e-01,\n",
      "        -2.5363e-01, -5.8247e-02,  2.2408e-01,  1.5920e-01, -5.6825e-02,\n",
      "         4.6530e-01, -2.1166e-01, -3.1839e-01, -1.2303e+00,  1.2068e-01,\n",
      "        -1.0088e-02,  3.3144e-01,  8.8529e-01, -5.0530e-02,  4.0095e-01,\n",
      "        -1.2923e-01, -6.6521e-02,  2.6929e-01,  2.9677e-01, -5.1512e-01,\n",
      "        -1.3941e-01,  3.3986e-02,  5.0526e-01,  2.3880e-01,  9.0405e-02,\n",
      "         2.8605e-01, -5.3700e-02, -2.3043e-01, -6.9528e-02,  6.2750e-02,\n",
      "        -8.3527e-02, -1.4610e-01,  1.8069e-01, -1.7798e-01, -9.7765e-02,\n",
      "        -6.4475e-03,  8.1148e-01,  2.0052e-01,  3.0710e-01, -2.3601e-01,\n",
      "         7.3178e-02,  1.1172e-01,  2.8366e-01,  6.6962e-02,  1.6107e-01,\n",
      "        -6.7723e-01,  1.3817e-01,  1.7344e-01, -4.4210e-02, -2.5060e-01,\n",
      "        -2.6521e-01,  1.6725e-01, -1.6838e-01, -8.5105e-02,  1.2462e-01,\n",
      "         4.2133e-02,  1.0998e-01,  4.3315e-01,  1.4762e-01, -2.2403e-02,\n",
      "         2.1770e-01,  5.9078e-02,  2.9927e-01,  8.4790e-02, -2.8061e-01,\n",
      "         3.7362e-02, -1.9944e-01, -4.8672e-01,  2.0394e-01,  1.9824e-01,\n",
      "         1.3828e-01,  3.0206e-02, -2.0721e-01,  7.0921e-01, -1.0912e-01,\n",
      "         4.8155e-01,  2.9200e-01,  4.7852e-02, -7.9537e-01, -4.4115e-02,\n",
      "         1.3331e-01, -1.9617e-01,  3.3779e-01,  4.0620e-01, -1.1334e-01,\n",
      "         5.1684e-02,  7.7361e-02,  2.6791e-01,  3.2820e-01,  1.8926e-01,\n",
      "        -2.1592e-02,  5.3141e-02, -2.4303e-01,  1.5920e-01,  5.7491e-01,\n",
      "         7.7323e-02, -7.1903e-03,  3.1149e-01,  3.3197e-02,  2.7632e-01,\n",
      "         1.4343e-01], requires_grad=True)\n",
      "8 features.10.weight Parameter containing:\n",
      "tensor([[[[ 4.5008e-03, -7.7347e-03, -1.5003e-02],\n",
      "          [-3.0285e-02, -4.4114e-02, -1.7563e-02],\n",
      "          [-1.4331e-02, -3.6714e-02, -5.2003e-02]],\n",
      "\n",
      "         [[ 3.3324e-02,  9.8262e-03, -6.4676e-03],\n",
      "          [ 1.4188e-02,  2.4336e-02,  3.1040e-02],\n",
      "          [-1.9439e-02,  1.9590e-02, -1.6543e-02]],\n",
      "\n",
      "         [[ 3.3328e-05, -6.3628e-04,  1.5421e-02],\n",
      "          [ 1.1260e-02,  5.7387e-04,  1.7457e-02],\n",
      "          [ 7.1211e-03,  1.0711e-03,  2.1856e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6804e-02, -2.1512e-02, -1.0703e-02],\n",
      "          [-1.0698e-02, -5.3842e-02, -1.9335e-02],\n",
      "          [ 1.6292e-02,  4.4939e-04,  6.5307e-05]],\n",
      "\n",
      "         [[ 1.2114e-03,  1.1926e-03, -1.7091e-03],\n",
      "          [-1.7243e-02, -2.7680e-02,  1.9918e-05],\n",
      "          [ 5.2268e-04, -1.6247e-03, -4.3989e-03]],\n",
      "\n",
      "         [[ 1.9892e-02,  2.9338e-02,  2.0883e-02],\n",
      "          [ 1.3522e-02,  3.1604e-02,  1.2854e-02],\n",
      "          [ 5.2760e-03,  1.2341e-02,  7.5441e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4208e-02,  2.3224e-03, -2.5112e-02],\n",
      "          [-7.6076e-03,  9.4883e-03, -4.6517e-03],\n",
      "          [ 1.3253e-02,  1.1511e-02, -1.4017e-02]],\n",
      "\n",
      "         [[ 2.1794e-02,  1.0763e-02,  1.1629e-02],\n",
      "          [ 4.1082e-02, -7.8142e-03,  1.9052e-02],\n",
      "          [ 6.6561e-02,  3.6654e-02,  2.0193e-03]],\n",
      "\n",
      "         [[-1.8703e-02, -4.9244e-02, -2.9182e-02],\n",
      "          [-1.5992e-02,  1.6744e-04,  4.5855e-03],\n",
      "          [-6.2261e-03,  4.1283e-03,  8.5156e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8011e-02, -7.3355e-02, -6.5635e-02],\n",
      "          [-5.9603e-02, -5.7514e-02, -4.2397e-02],\n",
      "          [-5.5825e-02, -6.3877e-02, -6.0623e-02]],\n",
      "\n",
      "         [[-3.6692e-02, -3.2975e-02, -1.0278e-02],\n",
      "          [-3.1835e-02, -5.3899e-03, -3.2266e-02],\n",
      "          [-3.2715e-02, -3.3150e-02, -2.8616e-02]],\n",
      "\n",
      "         [[-8.2592e-03, -2.5406e-02, -1.7791e-02],\n",
      "          [-1.1399e-02, -2.3384e-02, -1.1688e-02],\n",
      "          [-2.2682e-02, -3.1900e-02, -7.9640e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8231e-02, -2.9938e-02, -3.0918e-02],\n",
      "          [ 6.0674e-04, -4.5208e-02, -4.3832e-03],\n",
      "          [-6.0434e-03, -6.1846e-02, -1.4543e-02]],\n",
      "\n",
      "         [[ 1.3111e-02,  1.5979e-02, -5.2871e-03],\n",
      "          [-1.2694e-02,  1.2434e-03,  2.2471e-02],\n",
      "          [ 2.1080e-02, -6.7459e-03,  1.9622e-02]],\n",
      "\n",
      "         [[ 3.0896e-02, -3.0819e-02,  5.1553e-03],\n",
      "          [-5.7161e-04, -1.2514e-02,  2.3466e-02],\n",
      "          [ 2.5366e-02,  3.1077e-02,  2.8808e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0043e-02, -3.3691e-02, -3.3587e-02],\n",
      "          [-3.1222e-02, -4.3832e-02, -2.9784e-02],\n",
      "          [-5.5385e-02, -6.6676e-02, -5.1232e-02]],\n",
      "\n",
      "         [[-1.8431e-02, -1.0482e-02, -1.3102e-02],\n",
      "          [ 5.6541e-03, -2.6609e-02,  2.4034e-03],\n",
      "          [-2.3949e-02,  8.9346e-03,  3.3861e-03]],\n",
      "\n",
      "         [[ 5.7008e-03, -1.4837e-02,  1.3501e-03],\n",
      "          [-5.6762e-04,  6.3385e-03,  5.1770e-03],\n",
      "          [ 5.5514e-03, -1.4905e-03, -2.3526e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8694e-02, -5.8550e-03,  7.5898e-03],\n",
      "          [ 5.4762e-03, -5.1852e-02,  5.3048e-03],\n",
      "          [ 5.4274e-02, -3.1494e-03, -5.8523e-03]],\n",
      "\n",
      "         [[ 1.0686e-02, -1.6323e-02,  2.0675e-02],\n",
      "          [ 1.9367e-03, -3.2638e-02,  9.5754e-04],\n",
      "          [ 2.1652e-03,  2.7449e-02,  5.5060e-02]],\n",
      "\n",
      "         [[ 5.0755e-03, -2.6414e-02,  1.8585e-02],\n",
      "          [-2.5866e-03,  1.2334e-03,  4.8944e-03],\n",
      "          [ 5.3379e-04, -8.6257e-03, -2.3603e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3444e-02,  9.6432e-03,  1.7831e-02],\n",
      "          [-1.8331e-02, -5.7185e-02, -2.1030e-02],\n",
      "          [ 1.0187e-02, -3.0167e-02, -8.0193e-03]],\n",
      "\n",
      "         [[ 1.7629e-02,  2.5001e-02, -4.5713e-02],\n",
      "          [ 2.5250e-02,  3.9404e-02,  3.0033e-02],\n",
      "          [ 1.6265e-02,  5.3023e-02,  8.1163e-03]],\n",
      "\n",
      "         [[ 4.1792e-03,  8.5183e-03,  3.5242e-03],\n",
      "          [ 2.7552e-02,  4.5622e-02,  3.8444e-03],\n",
      "          [ 2.1285e-02,  2.0103e-02,  1.6193e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4135e-02, -3.3222e-02, -5.2931e-03],\n",
      "          [-8.9475e-03, -3.3265e-02,  4.3306e-03],\n",
      "          [ 1.7092e-02, -2.8524e-02, -2.5048e-02]],\n",
      "\n",
      "         [[-1.4275e-02, -2.7405e-02,  1.1635e-02],\n",
      "          [-2.2799e-02, -3.2017e-02, -9.8221e-03],\n",
      "          [-2.0387e-02, -3.1692e-02, -9.8188e-03]],\n",
      "\n",
      "         [[-2.0245e-02, -7.1923e-03,  5.0653e-03],\n",
      "          [ 9.2916e-03, -1.4393e-02, -2.8599e-02],\n",
      "          [ 1.5616e-03, -1.7386e-02, -7.2756e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4874e-02, -9.5781e-03,  2.7291e-02],\n",
      "          [ 1.7682e-03, -1.8440e-02,  7.5908e-03],\n",
      "          [-6.8078e-03, -1.3905e-03,  3.8714e-03]],\n",
      "\n",
      "         [[-2.7931e-02, -3.4299e-02, -1.5767e-02],\n",
      "          [-1.5908e-02, -4.4211e-02, -1.5330e-02],\n",
      "          [-1.9257e-02, -2.3017e-02,  7.2739e-04]],\n",
      "\n",
      "         [[-3.6868e-02,  1.5530e-02, -7.3656e-04],\n",
      "          [-3.2403e-03, -2.5565e-02, -6.2375e-04],\n",
      "          [-7.5825e-03, -1.7276e-02, -1.2110e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0703e-03, -3.1071e-02,  4.9807e-04],\n",
      "          [ 1.3618e-02,  6.6683e-03, -1.3059e-02],\n",
      "          [-1.5806e-02,  9.5659e-03, -2.8366e-02]],\n",
      "\n",
      "         [[-1.5622e-02,  1.0870e-02, -4.3911e-02],\n",
      "          [-6.0366e-03,  4.7041e-02, -6.7736e-03],\n",
      "          [ 2.3879e-02,  1.5275e-02,  2.1209e-02]],\n",
      "\n",
      "         [[-3.4367e-02, -2.7406e-03, -4.0337e-02],\n",
      "          [-2.1270e-02, -2.4037e-02, -2.0263e-02],\n",
      "          [-7.9488e-03, -1.4826e-03, -6.8217e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0063e-02, -2.2878e-02, -5.5036e-03],\n",
      "          [ 3.2441e-02, -1.3513e-02,  2.5942e-03],\n",
      "          [-2.8327e-02, -3.6309e-02, -1.9826e-02]],\n",
      "\n",
      "         [[-9.0379e-03,  1.6569e-02,  5.9027e-04],\n",
      "          [-7.4690e-04,  3.3369e-02,  2.2972e-02],\n",
      "          [ 1.0572e-02,  8.1467e-03, -3.4821e-02]],\n",
      "\n",
      "         [[ 7.4795e-03,  1.9532e-03,  8.9045e-03],\n",
      "          [-7.3107e-03, -2.9493e-02,  1.2008e-03],\n",
      "          [ 8.8704e-03,  1.1838e-02,  7.4983e-04]]]], requires_grad=True)\n",
      "9 features.10.bias Parameter containing:\n",
      "tensor([ 3.7964e-02,  4.3626e-01,  1.9919e-01,  4.7873e-01,  1.9452e-01,\n",
      "         4.6094e-02,  8.9556e-02, -9.0875e-02,  1.2068e-01,  1.8953e-01,\n",
      "         4.5016e-02,  4.8434e-01,  2.4634e-01, -7.8553e-02, -4.1008e-02,\n",
      "        -4.5605e-01,  6.7455e-01,  4.3669e-02, -3.8591e-01,  2.3154e-01,\n",
      "         1.2107e-01,  3.2227e-01,  1.1335e+00,  2.1153e-01,  4.7995e-01,\n",
      "         2.8958e-01,  6.4578e-02,  2.4041e-02,  1.5042e-01,  2.8817e-01,\n",
      "         6.7181e-02,  2.6940e-01,  1.0063e-02,  3.4250e-01,  1.6370e-01,\n",
      "         2.0520e-01,  7.5118e-02,  1.1070e-01,  2.6571e-01,  1.2281e-01,\n",
      "        -4.6485e-02,  5.1063e-01,  1.4461e-01,  4.4510e-01,  3.3639e-01,\n",
      "         4.0720e-01, -2.1050e-02,  1.1052e+00,  1.2309e-01,  3.1051e-01,\n",
      "         2.3018e-01,  3.6438e-01,  3.8058e-01,  1.7631e-01,  6.3093e-01,\n",
      "        -1.3756e-02,  2.6251e-01,  2.0362e-01,  3.4236e-01,  1.9062e-02,\n",
      "         1.5609e-01,  2.2937e-01, -8.7384e-02,  3.1602e-02,  8.6188e-02,\n",
      "         2.4748e-01, -7.8154e-03,  2.2365e-01,  2.4816e-01,  7.1836e-02,\n",
      "        -6.6000e-02, -6.8084e-02, -2.1012e-02,  4.0951e-01,  4.2487e-01,\n",
      "         3.0534e-01, -1.1383e-01,  2.4841e-02,  1.1446e-01,  7.3555e-03,\n",
      "        -4.6246e-02,  6.3487e-01, -1.1421e-01,  6.1986e-01,  9.2757e-02,\n",
      "        -1.4665e-02,  4.6250e-01,  6.3386e-01, -1.7848e-02,  1.3755e-01,\n",
      "         1.2155e-02,  1.9338e-01,  1.9085e-02,  8.1355e-02,  1.7102e-02,\n",
      "         4.4921e-02,  1.9130e-01,  2.0720e-01,  1.7913e-03,  4.5546e-01,\n",
      "         3.8208e-01,  3.2588e-01, -1.0084e-01,  5.0784e-01,  1.2523e-02,\n",
      "         5.9673e-01,  8.0652e-01,  4.6247e-01,  1.4344e-01,  9.7860e-03,\n",
      "        -3.8480e-02,  3.1713e-02,  1.3493e-01,  5.5403e-01,  1.3879e-01,\n",
      "         1.8507e-01,  3.5126e-02, -1.2923e-01,  1.5486e-01,  6.6569e-02,\n",
      "         2.2698e-01, -8.0724e-02,  5.2492e-01,  1.2118e-01,  2.5738e-02,\n",
      "         2.4021e+00,  5.4695e-01, -1.7379e-01,  1.0619e-01, -4.2293e-02,\n",
      "         3.7618e-02,  2.4259e-01, -7.6743e-02,  2.1944e-02,  4.8954e-01,\n",
      "         4.1475e-01,  4.8341e-02, -3.5894e-02,  1.4445e-01, -2.0989e-01,\n",
      "         2.6906e-01,  6.1454e-02,  4.7476e-03,  5.8720e-01,  2.1773e-01,\n",
      "         8.1851e-01,  4.1794e-01,  4.1514e-02,  1.7567e-01,  9.2828e-01,\n",
      "         1.3975e-01,  3.6809e-01,  6.7954e-01, -4.6613e-02,  6.1853e-01,\n",
      "         9.9139e-02,  3.7578e-01,  1.2078e-01,  7.3212e-01,  1.4217e-01,\n",
      "        -1.5891e-02,  4.9133e-01,  6.9460e-02,  1.6718e-01,  6.8328e-01,\n",
      "         3.6984e-01,  1.1704e-01,  4.6448e-03,  4.4395e-01,  1.6502e-01,\n",
      "         1.2848e-01,  2.1826e-01,  7.0516e-01,  4.1369e-03,  1.6124e-01,\n",
      "         1.1174e-01, -8.4453e-04,  2.6191e-01,  7.3103e-02,  2.6202e-01,\n",
      "         1.5253e-02,  2.0889e-01,  3.3991e-01,  3.9360e-02,  9.8699e-02,\n",
      "         2.8095e-01,  1.3300e-01, -9.8729e-02,  1.5865e-01, -1.0977e-01,\n",
      "        -1.2899e-01,  1.5089e-01,  1.3981e-01,  1.9367e-03,  1.0875e-01,\n",
      "        -1.6497e-01,  5.6130e-02,  1.7397e-01,  4.1817e-01,  1.1607e-01,\n",
      "         3.5296e-01,  8.5897e-01,  2.8839e-01,  1.1828e-01, -5.0673e-02,\n",
      "         2.8798e-02,  1.3510e-01,  1.9383e-01, -1.9312e-02,  5.4221e-01,\n",
      "         5.3677e-01,  4.4037e-01,  5.0655e-01,  3.5812e-01,  5.3000e-01,\n",
      "         5.1179e-01,  2.0096e-01,  3.6999e-01,  6.0126e-01,  4.2610e-03,\n",
      "         1.9014e-02, -1.7977e-01,  6.5511e-02,  6.4663e-01,  2.4109e-01,\n",
      "         1.3175e-01,  6.0788e-01, -4.4901e-03,  6.0372e-01,  2.9686e-01,\n",
      "         6.3624e-01,  3.3710e-01,  1.0049e-01,  4.1112e-01,  5.2909e-01,\n",
      "         1.8214e-01,  2.3342e-01,  3.5865e-02,  9.3808e-02,  1.6784e-01,\n",
      "         9.7704e-02,  4.3545e-01,  3.4650e-02, -7.2180e-02,  1.4837e-01,\n",
      "        -9.3362e-02,  4.1976e-01, -4.9194e-03,  1.8956e-01,  5.4447e-01,\n",
      "         5.3322e-01,  3.6115e-01,  3.2763e-01,  5.5909e-01,  2.0211e-03,\n",
      "        -6.6487e-02], requires_grad=True)\n",
      "10 classifier.1.weight Parameter containing:\n",
      "tensor([[ 0.0040,  0.0061,  0.0134,  ..., -0.0003, -0.0022, -0.0093],\n",
      "        [ 0.0013,  0.0020,  0.0028,  ...,  0.0053,  0.0002, -0.0145],\n",
      "        [-0.0185, -0.0145, -0.0198,  ..., -0.0003, -0.0012,  0.0191],\n",
      "        ...,\n",
      "        [-0.0063,  0.0026, -0.0084,  ..., -0.0079,  0.0055,  0.0067],\n",
      "        [-0.0115, -0.0055, -0.0092,  ..., -0.0039, -0.0048, -0.0099],\n",
      "        [ 0.0026, -0.0148, -0.0016,  ...,  0.0050,  0.0052, -0.0045]],\n",
      "       requires_grad=True)\n",
      "11 classifier.1.bias Parameter containing:\n",
      "tensor([ 0.0324,  0.0621, -0.0557,  ..., -0.0248,  0.0185,  0.0095],\n",
      "       requires_grad=True)\n",
      "12 classifier.4.weight Parameter containing:\n",
      "tensor([[-0.0107, -0.0015,  0.0057,  ...,  0.0026, -0.0010, -0.0087],\n",
      "        [-0.0279,  0.0168, -0.0162,  ..., -0.0079, -0.0049, -0.0219],\n",
      "        [-0.0112, -0.0184,  0.0073,  ...,  0.0013,  0.0050,  0.0055],\n",
      "        ...,\n",
      "        [-0.0027, -0.0146,  0.0057,  ...,  0.0250, -0.0042, -0.0009],\n",
      "        [ 0.0066,  0.0094,  0.0232,  ...,  0.0060, -0.0029, -0.0042],\n",
      "        [ 0.0118,  0.0041,  0.0013,  ..., -0.0088, -0.0039,  0.0055]],\n",
      "       requires_grad=True)\n",
      "13 classifier.4.bias Parameter containing:\n",
      "tensor([0.0489, 0.0972, 0.0022,  ..., 0.0261, 0.0448, 0.0802],\n",
      "       requires_grad=True)\n",
      "14 classifier.6.weight Parameter containing:\n",
      "tensor([[ 8.2334e-03, -7.2880e-03,  1.5556e-02,  ...,  6.8966e-03,\n",
      "         -2.5152e-03,  1.1945e-02],\n",
      "        [ 6.9816e-03, -2.8786e-03, -2.6394e-03,  ...,  1.5060e-04,\n",
      "         -1.4132e-02, -1.4835e-02],\n",
      "        [-1.0615e-02, -5.8698e-03,  1.3459e-02,  ...,  1.9780e-03,\n",
      "         -6.3718e-03,  8.6014e-03],\n",
      "        ...,\n",
      "        [-5.4216e-03,  3.5834e-05,  1.4301e-02,  ..., -7.0245e-03,\n",
      "          4.6273e-03, -2.7535e-03],\n",
      "        [ 7.6755e-03,  1.0764e-02,  6.0568e-03,  ...,  9.2243e-04,\n",
      "          9.3383e-03, -1.1211e-02],\n",
      "        [-1.2886e-02, -4.9216e-03,  1.5799e-03,  ..., -1.3405e-02,\n",
      "          4.8529e-03, -6.4688e-03]], requires_grad=True)\n",
      "15 classifier.6.bias Parameter containing:\n",
      "tensor([ 0.0115, -0.0026,  0.0128,  0.0086, -0.0027, -0.0142,  0.0006, -0.0022,\n",
      "         0.0153, -0.0065,  0.0009, -0.0087, -0.0073, -0.0155,  0.0140, -0.0089,\n",
      "        -0.0123, -0.0063, -0.0053, -0.0079, -0.0051,  0.0083, -0.0026, -0.0024,\n",
      "        -0.0094,  0.0143, -0.0010, -0.0092, -0.0097,  0.0069, -0.0055,  0.0053,\n",
      "        -0.0134,  0.0105, -0.0076,  0.0091, -0.0062,  0.0134,  0.0139,  0.0004,\n",
      "        -0.0039, -0.0030,  0.0078, -0.0044, -0.0069,  0.0135, -0.0127,  0.0075,\n",
      "         0.0115,  0.0103, -0.0044, -0.0110,  0.0143, -0.0146, -0.0026, -0.0034,\n",
      "         0.0091, -0.0031, -0.0122,  0.0013, -0.0003, -0.0118, -0.0152,  0.0111,\n",
      "        -0.0101, -0.0076, -0.0074, -0.0006, -0.0150, -0.0069, -0.0104,  0.0011,\n",
      "         0.0020, -0.0040, -0.0101, -0.0068, -0.0093, -0.0027, -0.0093, -0.0052,\n",
      "         0.0059,  0.0061, -0.0024, -0.0018,  0.0107,  0.0082, -0.0030,  0.0025,\n",
      "        -0.0055,  0.0106,  0.0116, -0.0114,  0.0093, -0.0027,  0.0061,  0.0017,\n",
      "        -0.0077,  0.0074,  0.0059, -0.0099, -0.0093], requires_grad=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEyL3H_R4qCf",
    "colab_type": "text"
   },
   "source": [
    "**Prepare Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9sjq00G94tSc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
    "\n",
    "# Choose parameters to optimize\n",
    "# To access a different set of parameters, you have to access submodules of AlexNet\n",
    "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
    "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
    "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
    "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
    "\n",
    "# Define optimizer\n",
    "# An optimizer updates the weights based on loss\n",
    "# We use SGD with momentum\n",
    "\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.Adam(parameters_to_optimize, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define scheduler\n",
    "# A scheduler dynamically changes learning rate\n",
    "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxYUli9d9uYQ",
    "colab_type": "text"
   },
   "source": [
    "**Train with Validation**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZcoQ5fD49yT_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# By default, everything is loaded to cpu\n",
    "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "cudnn.benchmark = True # Calling this optimizes runtime\n",
    "\n",
    "current_step = 0\n",
    "best_accuracy = 0\n",
    "loss_vector = []\n",
    "tot_accuracy = []\n",
    "# Start iterating over the epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
    "\n",
    "  # Iterate over the dataset\n",
    "  for images, labels in train_dataloader:\n",
    "    # Bring data over the device of choice\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    net.train().to(DEVICE) # Sets module in training mode\n",
    "\n",
    "    # PyTorch, by default, accumulates gradients after each backward pass\n",
    "    # We need to manually set the gradients to zero before starting a new iteration\n",
    "    optimizer.zero_grad() # Zero-ing the gradients\n",
    "\n",
    "    # Forward pass to the network\n",
    "    outputs = net(images)\n",
    "\n",
    "    # Compute loss based on output and ground truth\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Log loss\n",
    "    if current_step % LOG_FREQUENCY == 0:\n",
    "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "    # Compute gradients for each layer and update weights\n",
    "    loss.backward()  # backward pass: computes gradients\n",
    "    optimizer.step() # update weights based on accumulated gradients\n",
    "\n",
    "    current_step += 1\n",
    "\n",
    "  loss_vector.append(loss.item())\n",
    "\n",
    "  # Step the scheduler\n",
    "  scheduler.step()\n",
    "\n",
    "  #VALIDATION\n",
    "  net.train(False) # Set Network to evaluation mode\n",
    "\n",
    "  running_corrects = 0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in tqdm(val_dataloader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = net(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update Corrects\n",
    "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "  # Calculate Accuracy\n",
    "  accuracy = running_corrects / float(len(val_dataset))\n",
    "  tot_accuracy.append(accuracy)\n",
    "  print('Test Accuracy: {}'.format(accuracy))\n",
    "\n",
    "  if accuracy>best_accuracy:\n",
    "    best_net = copy.deepcopy(net)\n",
    "    best_accuracy=accuracy"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiC\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "100%|██████████| 46/46 [00:25<00:00,  1.84it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.95it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.92it/s]\n",
      "100%|██████████| 46/46 [00:24<00:00,  1.91it/s]\n",
      "100%|██████████| 46/46 [00:24<00:00,  1.91it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.97it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.94it/s]\n",
      "100%|██████████| 46/46 [00:24<00:00,  1.90it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.97it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.00it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.03it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.93it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.98it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.97it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.06it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.04it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.05it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.03it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.06it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/20, LR = [0.01]\n",
      "Step 0, Loss 4.996925354003906\n",
      "Step 10, Loss 6.390196800231934\n",
      "Step 20, Loss 6.60787296295166\n",
      "Step 30, Loss 4.670514106750488\n",
      "Step 40, Loss 5.967083930969238\n",
      "Test Accuracy: 0.19536652835408022\n",
      "Starting epoch 2/20, LR = [0.01]\n",
      "Step 50, Loss 15.29195499420166\n",
      "Step 60, Loss 7.818288803100586\n",
      "Step 70, Loss 10.478059768676758\n",
      "Step 80, Loss 4.971889972686768\n",
      "Test Accuracy: 0.23167358229598894\n",
      "Starting epoch 3/20, LR = [0.01]\n",
      "Step 90, Loss 6.543590068817139\n",
      "Step 100, Loss 7.1751708984375\n",
      "Step 110, Loss 7.026226997375488\n",
      "Step 120, Loss 4.024662017822266\n",
      "Step 130, Loss 3.8761861324310303\n",
      "Test Accuracy: 0.229253112033195\n",
      "Starting epoch 4/20, LR = [0.01]\n",
      "Step 140, Loss 4.45176887512207\n",
      "Step 150, Loss 4.0212178230285645\n",
      "Step 160, Loss 4.098968505859375\n",
      "Step 170, Loss 3.7619688510894775\n",
      "Test Accuracy: 0.1946749654218534\n",
      "Starting epoch 5/20, LR = [0.01]\n",
      "Step 180, Loss 4.1701579093933105\n",
      "Step 190, Loss 4.434141635894775\n",
      "Step 200, Loss 4.175826072692871\n",
      "Step 210, Loss 3.8515307903289795\n",
      "Step 220, Loss 4.70365571975708\n",
      "Test Accuracy: 0.2143845089903181\n",
      "Starting epoch 6/20, LR = [0.0001]\n",
      "Step 230, Loss 4.256601333618164\n",
      "Step 240, Loss 3.964163303375244\n",
      "Step 250, Loss 4.2528395652771\n",
      "Step 260, Loss 4.221536159515381\n",
      "Test Accuracy: 0.21749654218533887\n",
      "Starting epoch 7/20, LR = [0.001]\n",
      "Step 270, Loss 3.8344228267669678\n",
      "Step 280, Loss 3.458115816116333\n",
      "Step 290, Loss 3.816458225250244\n",
      "Step 300, Loss 3.5633656978607178\n",
      "Step 310, Loss 4.129365921020508\n",
      "Test Accuracy: 0.21784232365145229\n",
      "Starting epoch 8/20, LR = [0.001]\n",
      "Step 320, Loss 4.093145370483398\n",
      "Step 330, Loss 3.96114182472229\n",
      "Step 340, Loss 3.611821174621582\n",
      "Step 350, Loss 3.9323978424072266\n",
      "Test Accuracy: 0.2289073305670816\n",
      "Starting epoch 9/20, LR = [0.001]\n",
      "Step 360, Loss 4.375437259674072\n",
      "Step 370, Loss 5.518742084503174\n",
      "Step 380, Loss 5.627264022827148\n",
      "Step 390, Loss 5.0806884765625\n",
      "Step 400, Loss 3.998084783554077\n",
      "Test Accuracy: 0.22302904564315354\n",
      "Starting epoch 10/20, LR = [0.001]\n",
      "Step 410, Loss 4.038848400115967\n",
      "Step 420, Loss 3.6952426433563232\n",
      "Step 430, Loss 4.976446151733398\n",
      "Step 440, Loss 4.143752574920654\n",
      "Test Accuracy: 0.27835408022130015\n",
      "Starting epoch 11/20, LR = [1e-05]\n",
      "Step 450, Loss 3.286165714263916\n",
      "Step 460, Loss 3.641522169113159\n",
      "Step 470, Loss 3.6202478408813477\n",
      "Step 480, Loss 3.7806918621063232\n",
      "Step 490, Loss 3.970567226409912\n",
      "Test Accuracy: 0.279045643153527\n",
      "Starting epoch 12/20, LR = [0.0001]\n",
      "Step 500, Loss 3.4797873497009277\n",
      "Step 510, Loss 3.6435916423797607\n",
      "Step 520, Loss 3.9771132469177246\n",
      "Step 530, Loss 3.620966911315918\n",
      "Test Accuracy: 0.28284923928077454\n",
      "Starting epoch 13/20, LR = [0.0001]\n",
      "Step 540, Loss 3.5122804641723633\n",
      "Step 550, Loss 3.861945629119873\n",
      "Step 560, Loss 3.463440418243408\n",
      "Step 570, Loss 3.679100275039673\n",
      "Step 580, Loss 3.29121470451355\n",
      "Test Accuracy: 0.28526970954356845\n",
      "Starting epoch 14/20, LR = [0.0001]\n",
      "Step 590, Loss 3.561171054840088\n",
      "Step 600, Loss 3.4007675647735596\n",
      "Step 610, Loss 3.9803836345672607\n",
      "Step 620, Loss 3.266265869140625\n",
      "Test Accuracy: 0.2918395573997234\n",
      "Starting epoch 15/20, LR = [0.0001]\n",
      "Step 630, Loss 3.53757381439209\n",
      "Step 640, Loss 3.554919481277466\n",
      "Step 650, Loss 3.391730785369873\n",
      "Step 660, Loss 3.830496311187744\n",
      "Step 670, Loss 2.926687717437744\n",
      "Test Accuracy: 0.29564315352697096\n",
      "Starting epoch 16/20, LR = [1.0000000000000002e-06]\n",
      "Step 680, Loss 3.380798816680908\n",
      "Step 690, Loss 2.8664162158966064\n",
      "Step 700, Loss 8.619152069091797\n",
      "Step 710, Loss 3.4561402797698975\n",
      "Test Accuracy: 0.2963347164591978\n",
      "Starting epoch 17/20, LR = [1e-05]\n",
      "Step 720, Loss 4.186579704284668\n",
      "Step 730, Loss 3.275264024734497\n",
      "Step 740, Loss 3.6062347888946533\n",
      "Step 750, Loss 3.656430959701538\n",
      "Step 760, Loss 3.567281484603882\n",
      "Test Accuracy: 0.29564315352697096\n",
      "Starting epoch 18/20, LR = [1e-05]\n",
      "Step 770, Loss 3.269190549850464\n",
      "Step 780, Loss 3.4414212703704834\n",
      "Step 790, Loss 3.387570381164551\n",
      "Step 800, Loss 3.4263367652893066\n",
      "Test Accuracy: 0.2984094052558783\n",
      "Starting epoch 19/20, LR = [1e-05]\n",
      "Step 810, Loss 3.706322193145752\n",
      "Step 820, Loss 3.542531967163086\n",
      "Step 830, Loss 3.2667529582977295\n",
      "Step 840, Loss 3.490546464920044\n",
      "Step 850, Loss 3.2801709175109863\n",
      "Test Accuracy: 0.2970262793914246\n",
      "Starting epoch 20/20, LR = [1e-05]\n",
      "Step 860, Loss 3.5265350341796875\n",
      "Step 870, Loss 3.353325366973877\n",
      "Step 880, Loss 3.684938669204712\n",
      "Step 890, Loss 2.963135242462158\n",
      "Test Accuracy: 0.29529737206085754\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plots**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_name = 'AlexNet ConvLFreezed Aug(10crop, greyscale)- BS= %d LR= %e  EPOCHS= %d  STEP= %d' % (BATCH_SIZE, LR, NUM_EPOCHS, STEP_SIZE)\n",
    "pd.DataFrame(tot_accuracy, loss_vector).to_csv('./Results/ %s.csv' % csv_name)\n",
    "plt.plot(tot_accuracy)\n",
    "plt.show()\n",
    "plt.plot(loss_vector)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsHFI-GAJd69",
    "colab_type": "text"
   },
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fSHcUqLB5yWO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "net = best_net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "net.train(False) # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "  images = images.to(DEVICE)\n",
    "  labels = labels.to(DEVICE)\n",
    "\n",
    "  # Forward Pass\n",
    "  outputs = net(images)\n",
    "\n",
    "  # Get predictions\n",
    "  _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "  # Update Corrects\n",
    "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(test_dataset))\n",
    "\n",
    "print('Test Accuracy: {}'.format(accuracy))"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:16<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.29623228482544073\n"
     ]
    }
   ]
  }
 ]
}